{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Pipeline\n",
    "\n",
    "### Select a Task\n",
    "\n",
    "### Load the Pipeline\n",
    "\n",
    "### Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-20 15:06:49.879491: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 629/629 [00:00<00:00, 88.5kB/s]\n",
      "model.safetensors: 100%|██████████| 268M/268M [00:32<00:00, 8.20MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 9.38kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 2.96MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment from task_pipeline: NEGATIVE; Sentiment from model_pipeline: NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Import pipeline\n",
    "# --------------------\n",
    "from transformers import pipeline\n",
    "\n",
    "# --------------------\n",
    "# Create the task pipeline\n",
    "# --------------------\n",
    "task_pipeline = pipeline(task=\"sentiment-analysis\")\n",
    "\n",
    "# --------------------\n",
    "# Create the model pipeline\n",
    "# --------------------\n",
    "model_pipeline = pipeline(model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "text = \"this a non sentence. I am not sure what to do with it.\"\n",
    "\n",
    "# --------------------\n",
    "# Predict the sentiment\n",
    "# --------------------\n",
    "task_output = task_pipeline(text)\n",
    "model_output = model_pipeline(text)\n",
    "\n",
    "print(f\"Sentiment from task_pipeline: {task_output[0]['label']}; Sentiment from model_pipeline: {model_output[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label     score                                               text\n",
      "0  NEGATIVE  0.999614  this a non sentence. I am not sure what to do ...\n",
      "1  POSITIVE  0.999875                              I am happy to be here\n"
     ]
    }
   ],
   "source": [
    "text1 = [\"this a non sentence. I am not sure what to do with it.\", \"I am happy to be here\"]\n",
    "\n",
    "# Predict the sentiment of multiple sentences\n",
    "task_output = task_pipeline(text1)\n",
    "model_output = model_pipeline(text1)\n",
    "\n",
    "import pandas as pd\n",
    "# convert the output to a dataframe including the text\n",
    "df = pd.DataFrame(task_output)\n",
    "df[\"text\"] = text1\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a different model other than the default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 483/483 [00:00<00:00, 76.2kB/s]\n",
      "model.safetensors: 100%|██████████| 268M/268M [00:19<00:00, 14.0MB/s] \n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 4.32kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 12.4MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 11.4MB/s]\n",
      "config.json: 100%|██████████| 1.00k/1.00k [00:00<00:00, 604kB/s]\n",
      "/Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "pytorch_model.bin: 100%|██████████| 438M/438M [00:34<00:00, 12.8MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 1.19k/1.19k [00:00<00:00, 158kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 25.5MB/s]\n",
      "tokenizer.json: 100%|██████████| 711k/711k [00:00<00:00, 19.9MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 65.6kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label     score                                               text\n",
      "0  LABEL_1  0.514635  this a non sentence. I am not sure what to do ...\n",
      "1  LABEL_1  0.504306                              I am happy to be here\n",
      "                label     score  \\\n",
      "0            Negative  0.972048   \n",
      "1  Extremely Positive  0.995910   \n",
      "\n",
      "                                                text  \n",
      "0  this a non sentence. I am not sure what to do ...  \n",
      "1                              I am happy to be here  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "distilbert_pipeline = pipeline(model=\"distilbert-base-uncased\", task=\"sentiment-analysis\")\n",
    "distilbert_output = distilbert_pipeline(text1)\n",
    "df_2 = pd.DataFrame(distilbert_output)\n",
    "df_2[\"text\"] = text1\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# And another model \n",
    "# -------------------\n",
    "bert_pipeline = pipeline(model=\"kwang123/bert-sentiment-analysis\", task=\"sentiment-analysis\")\n",
    "bert_output = bert_pipeline(text1)\n",
    "df_3 = pd.DataFrame(bert_output)\n",
    "df_3[\"text\"] = text1\n",
    "\n",
    "\n",
    "print(df_2)\n",
    "print(df_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import a small random subset of the sentinments df (1000 reviews)\n",
    "\n",
    "### Apply Sentiment analysis on 10, 100 and then 1000 reviews and extrapolate the time it would take for a large (1M) number of reviews\n",
    "\n",
    "### Find another model on the portal and repeat the above step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            reviewerID        asin                      reviewerName helpful  \\\n",
      "102773  A1M7VLUUTO1NRL  B004GSYAIA                   Amazon Customer  [0, 0]   \n",
      "52396   A1MEXN4Q7ZPPM5  B000O7HHRS                    JON DOE, TEXAS  [0, 0]   \n",
      "48382   A2OX2RGNCJDDQN  B000XRCMYW        Karen C. Hogan \"Book Diva\"  [0, 0]   \n",
      "27286   A1CIMOIAZUR7CP  B000GX1TPQ                        ChristieL.  [0, 0]   \n",
      "55577    A25TYZ1P8UWXR  B001618J50                       R. Folkerts  [2, 2]   \n",
      "...                ...         ...                               ...     ...   \n",
      "56616   A33OF5NLPRZ5YT  B0017U1MJU  M. Bishopski \"Lost in the Woods\"  [1, 1]   \n",
      "236565   AQOFLJ2IOMOO8  B00ABS67T4                Sipeish \"SD mamma\"  [2, 2]   \n",
      "99472   A2OECBTX7KM6FJ  B0043WVTNI                     NW Washington  [1, 1]   \n",
      "74901   A1YETX467CJV00  B0020HRYYG                          P. Smith  [0, 0]   \n",
      "35415   A29GWIJL72GXXZ  B000COYDU2                               Jon  [0, 0]   \n",
      "\n",
      "                                               reviewText  overall  \\\n",
      "102773  Reason for the 4 stars is that the material fe...      4.0   \n",
      "52396   ARRIVED ON TIME...VERY LIGHT WEIGHT (and i mea...      3.0   \n",
      "48382   The shoes are exactly what I expected. They ar...      4.0   \n",
      "27286   After my favorite expensive leather wallet sto...      5.0   \n",
      "55577   Nice conventional jeans.  Nothing fancy.  They...      4.0   \n",
      "...                                                   ...      ...   \n",
      "56616   Finally a Pathfinder with solar technology.  I...      5.0   \n",
      "236565  They go all the way my thighs like I wanted th...      5.0   \n",
      "99472   We like buying Delta faucets as they have alwa...      5.0   \n",
      "74901   The first washing of these socks left them cov...      3.0   \n",
      "35415   Not very smooth transition of color.  Too larg...      1.0   \n",
      "\n",
      "                                                  summary  unixReviewTime  \\\n",
      "102773                                        Works great      1395100800   \n",
      "52396                                     \"HOPE IT WORKS\"      1370736000   \n",
      "48382                                        A GOOD GIFT.      1352764800   \n",
      "27286                                      Perfect for Me      1376611200   \n",
      "55577                                         Good jeans!      1367280000   \n",
      "...                                                   ...             ...   \n",
      "56616          Finally a Pathfinder with solar technology      1396051200   \n",
      "236565                                               Nice      1365120000   \n",
      "99472                                  More Delta faucets      1330214400   \n",
      "74901                                  Good But Not Great      1350086400   \n",
      "35415   Didn't like it ... THEN IT JUST BROKE AFTER 5 ...      1261699200   \n",
      "\n",
      "         reviewTime   category  \n",
      "102773  03 18, 2014  Category2  \n",
      "52396    06 9, 2013  Category2  \n",
      "48382   11 13, 2012  Category1  \n",
      "27286   08 16, 2013  Category1  \n",
      "55577   04 30, 2013  Category1  \n",
      "...             ...        ...  \n",
      "56616   03 29, 2014  Category1  \n",
      "236565   04 5, 2013  Category1  \n",
      "99472   02 26, 2012  Category2  \n",
      "74901   10 13, 2012  Category1  \n",
      "35415   12 25, 2009  Category2  \n",
      "\n",
      "[1000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Replace these with the paths to your actual JSON files\n",
    "file_path1 = '../A3/Clothing_Shoes_and_Jewelry_5.json'\n",
    "file_path2 = 'reviews_Tools_and_Home_Improvement_5.json'\n",
    "\n",
    "# Load the JSON files into DataFrames\n",
    "\n",
    "data1 = []\n",
    "with open(file_path1, 'r') as f:\n",
    "        for line in f:\n",
    "            data1.append(json.loads(line))\n",
    "            \n",
    "df1 = pd.DataFrame(data1)\n",
    "data2 = []\n",
    "with open(file_path2, 'r') as f:\n",
    "        for line in f:\n",
    "            data2.append(json.loads(line))\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Add a new category column to each DataFrame\n",
    "df1['category'] = 'Category1'  # Name this category according to what it represents\n",
    "df2['category'] = 'Category2'  # Name this category accordingly\n",
    "\n",
    "# Concatenate the DataFrames along the rows (axis=0)\n",
    "combined_df = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "# Set a fixed seed and sample 1000 rows\n",
    "random_seed = 42\n",
    "if len(combined_df) >= 1000:\n",
    "    sample_df = combined_df.sample(n=1000, random_state=random_seed)\n",
    "else:\n",
    "    print(f\"The combined file has only {len(combined_df)} rows. Sampling the entire DataFrame.\")\n",
    "    sample_df = combined_df\n",
    "\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"bert-base-uncased\"  # Example model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "distilbert_pipeline = pipeline(model=\"distilbert-base-uncased\", task=\"sentiment-analysis\", truncation=True, max_length=512)\n",
    "def apply_tokenizer(text):\n",
    "\toutput = distilbert_pipeline(text)\n",
    "\t# print(output)\n",
    "\treturn output\n",
    "\t# inputs = tokenizer(text, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\t# output = model(**inputs)\n",
    "\t# print(inputs)\n",
    "\t# return output\n",
    "# text = \"your very long text\"  # Replace with your actual text\n",
    "\n",
    "# # Tokenize and truncate the input text\n",
    "# inputs = tokenizer(text, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# # Run the model\n",
    "# output = model(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 10 reviews: 0.5266578197479248 seconds\n",
      "Estimated time for 1 million reviews: 877.763032913208 minutes\n",
      "Time taken for 100 reviews: 3.5510311126708984 seconds\n",
      "Estimated time for 1 million reviews: 591.838518778483 minutes\n",
      "Time taken for 1000 reviews: 37.16049027442932 seconds\n",
      "Estimated time for 1 million reviews: 619.341504573822 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Mock function and data for demonstration\n",
    "def analyze_sentiment(df):\n",
    "\t# df['sentiment'] = df['reviewText'].apply(lambda x: task_pipeline(x)[0])\n",
    "\t# df['sentiment'] = df['reviewText'].apply(lambda x: model_pipeline(x)[0])\n",
    "\t# df['sentiment'] = df['reviewText'].apply(lambda x: bert_pipeline(x)[0])\n",
    "\tdf['sentiment'] = df['reviewText'].apply(lambda x: apply_tokenizer(x)[0])\n",
    "\n",
    "\t# The result is a dictionary with keys 'label' and 'score', you can split these into separate columns if needed\n",
    "\tdf['sentiment_label'] = df['sentiment'].apply(lambda x: x['label'])\n",
    "\tdf['sentiment_score'] = df['sentiment'].apply(lambda x: x['score'])\n",
    "\n",
    "# Generate dummy reviews for demonstration\n",
    "reviews = [\"This product is great!\" for _ in range(1000000)]  # Assume 1 million reviews\n",
    "\n",
    "for n in [10, 100, 1000]:\n",
    "    start_time = time.time()\n",
    "    results = analyze_sentiment(sample_df.sample(n=n, random_state=7))\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    print(f\"Time taken for {n} reviews: {time_taken} seconds\")\n",
    "\n",
    "    # Extrapolate to 1 million reviews\n",
    "    extrapolated_time = (time_taken / n) * 1000000\n",
    "    print(f\"Estimated time for 1 million reviews: {extrapolated_time / 60} minutes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keras3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
