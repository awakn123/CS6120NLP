{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Category1    678\n",
      "Category2    322\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Replace these with the paths to your actual JSON files\n",
    "file_path1 = '../A3/Clothing_Shoes_and_Jewelry_5.json'\n",
    "file_path2 = 'reviews_Tools_and_Home_Improvement_5.json'\n",
    "\n",
    "# Load the JSON files into DataFrames\n",
    "\n",
    "data1 = []\n",
    "with open(file_path1, 'r') as f:\n",
    "        for line in f:\n",
    "            data1.append(json.loads(line))\n",
    "            \n",
    "df1 = pd.DataFrame(data1)\n",
    "data2 = []\n",
    "with open(file_path2, 'r') as f:\n",
    "        for line in f:\n",
    "            data2.append(json.loads(line))\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Add a new category column to each DataFrame\n",
    "df1['category'] = 'Category1'  # Name this category according to what it represents\n",
    "df2['category'] = 'Category2'  # Name this category accordingly\n",
    "\n",
    "# Concatenate the DataFrames along the rows (axis=0)\n",
    "combined_df = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "# Set a fixed seed and sample 1000 rows\n",
    "random_seed = 42\n",
    "if len(combined_df) >= 1000:\n",
    "    sample_df = combined_df.sample(n=1000, random_state=random_seed)\n",
    "else:\n",
    "    print(f\"The combined file has only {len(combined_df)} rows. Sampling the entire DataFrame.\")\n",
    "    sample_df = combined_df\n",
    "\n",
    "# Count occurrences of each category in the sample\n",
    "category_counts = sample_df['category'].value_counts()\n",
    "\n",
    "print(category_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.3\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "print(huggingface_hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelInfo(id='albert/albert-base-v1', author=None, sha=None, created_at=datetime.datetime(2022, 3, 3, 0, 29, 4, tzinfo=datetime.timezone.utc), last_modified=None, private=False, gated=None, disabled=None, downloads=19052, likes=6, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'safetensors', 'albert', 'fill-mask', 'exbert', 'en', 'dataset:bookcorpus', 'dataset:wikipedia', 'arxiv:1909.11942', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='fill-mask', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, siblings=None, spaces=None, safetensors=None)\n",
      "ModelInfo(id='albert/albert-base-v2', author=None, sha=None, created_at=datetime.datetime(2022, 3, 3, 0, 29, 4, tzinfo=datetime.timezone.utc), last_modified=None, private=False, gated=None, disabled=None, downloads=2317512, likes=86, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'jax', 'rust', 'safetensors', 'albert', 'fill-mask', 'en', 'dataset:bookcorpus', 'dataset:wikipedia', 'arxiv:1909.11942', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'has_space', 'region:us'], pipeline_tag='fill-mask', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, siblings=None, spaces=None, safetensors=None)\n",
      "ModelInfo(id='albert/albert-large-v1', author=None, sha=None, created_at=datetime.datetime(2022, 3, 3, 0, 29, 4, tzinfo=datetime.timezone.utc), last_modified=None, private=False, gated=None, disabled=None, downloads=2344, likes=2, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'albert', 'fill-mask', 'en', 'dataset:bookcorpus', 'dataset:wikipedia', 'arxiv:1909.11942', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='fill-mask', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, siblings=None, spaces=None, safetensors=None)\n",
      "ModelInfo(id='albert/albert-large-v2', author=None, sha=None, created_at=datetime.datetime(2022, 3, 3, 0, 29, 4, tzinfo=datetime.timezone.utc), last_modified=None, private=False, gated=None, disabled=None, downloads=8568, likes=13, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'safetensors', 'albert', 'fill-mask', 'en', 'dataset:bookcorpus', 'dataset:wikipedia', 'arxiv:1909.11942', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='fill-mask', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, siblings=None, spaces=None, safetensors=None)\n",
      "ModelInfo(id='albert/albert-xlarge-v1', author=None, sha=None, created_at=datetime.datetime(2022, 3, 3, 0, 29, 4, tzinfo=datetime.timezone.utc), last_modified=None, private=False, gated=None, disabled=None, downloads=1719, likes=3, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'safetensors', 'albert', 'fill-mask', 'en', 'dataset:bookcorpus', 'dataset:wikipedia', 'arxiv:1909.11942', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='fill-mask', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, siblings=None, spaces=None, safetensors=None)\n",
      "ModelInfo(id='albert/albert-xlarge-v2', author=None, sha=None, created_at=datetime.datetime(2022, 3, 3, 0, 29, 4, tzinfo=datetime.timezone.utc), last_modified=None, private=False, gated=None, disabled=None, downloads=2547, likes=4, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'albert', 'fill-mask', 'en', 'dataset:bookcorpus', 'dataset:wikipedia', 'arxiv:1909.11942', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='fill-mask', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, siblings=None, spaces=None, safetensors=None)\n",
      "ModelInfo(id='albert/albert-xxlarge-v1', author=None, sha=None, created_at=datetime.datetime(2022, 3, 3, 0, 29, 4, tzinfo=datetime.timezone.utc), last_modified=None, private=False, gated=None, disabled=None, downloads=2997, likes=4, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'albert', 'fill-mask', 'en', 'dataset:bookcorpus', 'dataset:wikipedia', 'arxiv:1909.11942', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='fill-mask', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, siblings=None, spaces=None, safetensors=None)\n",
      "ModelInfo(id='albert/albert-xxlarge-v2', author=None, sha=None, created_at=datetime.datetime(2022, 3, 3, 0, 29, 4, tzinfo=datetime.timezone.utc), last_modified=None, private=False, gated=None, disabled=None, downloads=16583, likes=15, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'rust', 'safetensors', 'albert', 'fill-mask', 'exbert', 'en', 'dataset:bookcorpus', 'dataset:wikipedia', 'arxiv:1909.11942', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'has_space', 'region:us'], pipeline_tag='fill-mask', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, siblings=None, spaces=None, safetensors=None)\n",
      "ModelInfo(id='google-bert/bert-base-cased-finetuned-mrpc', author=None, sha=None, created_at=datetime.datetime(2022, 3, 3, 0, 29, 4, tzinfo=datetime.timezone.utc), last_modified=None, private=False, gated=None, disabled=None, downloads=26110, likes=1, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'jax', 'safetensors', 'bert', 'fill-mask', 'autotrain_compatible', 'endpoints_compatible', 'has_space', 'region:us'], pipeline_tag='fill-mask', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, siblings=None, spaces=None, safetensors=None)\n",
      "ModelInfo(id='google-bert/bert-base-cased', author=None, sha=None, created_at=datetime.datetime(2022, 3, 3, 0, 29, 4, tzinfo=datetime.timezone.utc), last_modified=None, private=False, gated=None, disabled=None, downloads=5347529, likes=202, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'jax', 'safetensors', 'bert', 'fill-mask', 'exbert', 'en', 'dataset:bookcorpus', 'dataset:wikipedia', 'arxiv:1810.04805', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'has_space', 'region:us'], pipeline_tag='fill-mask', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, siblings=None, spaces=None, safetensors=None)\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "\n",
    "models = api.list_models(limit = 10)\n",
    "for model in models:\n",
    "\t\tprint(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
