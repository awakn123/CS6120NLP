{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "y = df['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use RandomizedSearchCV for hyperparameter tuning to find the best parameters for our model. RandomizedSearchCV performs an exhaustive search over the specified parameter grid, and best_params_ gives us the best parameters found during the search.\n",
    "In this model, we also tune the following hyperparameter parameters. By choosing these parameters, we tune our Random Forest model to achieve the best performance.\n",
    "we’ve chosen [10, 20] as possible values for n_estimators, which means the RandomizedSearchCV will try both 10 and 20 trees and see which one works better. We’ve chosen [None, 10] as possible values for max_depth, which means the RandomizedSearchCV will try both unlimited depth and a maximum depth of 10. min_samples_split is the minimum number of samples required to split an internal node.we’ve chosen [2, 5] as possible values, which means the RandomizedSearchCV will try splitting nodes with a minimum of 2 samples and a minimum of 5 samples. we’ve chosen [1, 2] as possible values for min_samples_leaf, which means the RandomizedSearchCV will try both a minimum of 1 sample and a minimum of 2 samples in a leaf node.\n",
    "Cross-validation(cv) is the number of cross-validation folds to use, which estimates the performance of the model on unseen data. Scoring is the metric to use to evaluate the performance of your model. In this case, we’re using accuracy.The n_iter parameter in RandomizedSearchCV determines the number of parameter settings that are sampled. Randomized search is a way to save time compared to grid search, which tries every single combination of parameters. random_state is used for reproducibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5448861738175917\n",
      "Precision: 0.579680871093444\n",
      "Recall: 0.5448861738175917\n",
      "F1 Score: 0.49588607669881146\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_distributions = {\n",
    "    'n_estimators': [10, 20],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2],  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Create the randomized search object\n",
    "random_search = RandomizedSearchCV(estimator=clf, param_distributions=param_distributions, cv=3, scoring='accuracy', n_iter=5, random_state=42)\n",
    "\n",
    "# Fit the randomized search object to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Train a new classifier using the best parameters\n",
    "clf_best = RandomForestClassifier(**best_params)\n",
    "clf_best.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf_best.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('F1 Score:', f1_score(y_test, y_pred, average='weighted'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
