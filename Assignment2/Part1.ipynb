{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Data Preprocessing:\n",
    "1.1 Load the dataset and perform initial exploration to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                           headline   category  \\\n",
      "0           0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
      "1           1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
      "2           2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
      "3           3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
      "4           4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
      "\n",
      "                                   short_description               authors  \\\n",
      "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
      "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
      "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
      "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
      "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
      "\n",
      "         date  headline_length  short_description_length  \n",
      "0  2022-09-23               76                       154  \n",
      "1  2022-09-23               89                       159  \n",
      "2  2022-09-23               69                        64  \n",
      "3  2022-09-23               56                       159  \n",
      "4  2022-09-22               77                       156  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('News_Category_Dataset_v3.csv')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Clean the text data, including removing special characters, stopwords, and applying lowercasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Yue\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    # remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    # remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# clean data\n",
    "df['cleaned_headline'] = df['headline'].apply(clean_text)\n",
    "df['cleaned_description'] = df['short_description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Perform text tokenization and vectorization using TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_headline = tfidf_vectorizer.fit_transform(df['cleaned_headline'])\n",
    "# df_headline_tfidf = pd.DataFrame(tfidf_headline.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "# df_headline_tfidf = df_headline_tfidf.add_prefix('headline_')\n",
    "\n",
    "tfidf_description = tfidf_vectorizer.fit_transform(df['cleaned_description'])\n",
    "# df_description_tfidf = pd.DataFrame(tfidf_description.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "# df_description_tfidf = df_description_tfidf.add_prefix('description_')\n",
    "\n",
    "# df = pd.concat([df, df_headline_tfidf, df_description_tfidf], axis=1)\n",
    "tfidf= hstack([tfidf_headline,tfidf_description])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Extract and analyze different features from the text that might be useful for classification, such as word count,\n",
    "sentence length, n-grams, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t2022.0\n",
      "  (0, 1)\t9.0\n",
      "  (0, 2)\t23.0\n",
      "  (0, 3)\t76.0\n",
      "  (0, 4)\t154.0\n",
      "  (0, 5)\t11.0\n",
      "  (0, 6)\t29.0\n",
      "  (0, 6525)\t0.43411106347172085\n",
      "  (0, 11816)\t0.2930364348388803\n",
      "  (0, 49772)\t0.34715627086759526\n",
      "  (0, 35589)\t0.4295348408110416\n",
      "  (0, 46307)\t0.4452883710668971\n",
      "  (0, 42984)\t0.31920292699930125\n",
      "  (0, 2376)\t0.2458235223031094\n",
      "  (0, 32366)\t0.24506760378570813\n",
      "  (0, 80367)\t0.21098028126920687\n",
      "  (0, 104497)\t0.27133950808906415\n",
      "  (0, 65448)\t0.3839295355670428\n",
      "  (0, 102558)\t0.13315756767983997\n",
      "  (0, 76636)\t0.32170408678838597\n",
      "  (0, 99768)\t0.19974144063358404\n",
      "  (0, 56745)\t0.3839295355670428\n",
      "  (0, 98192)\t0.2572541275751765\n",
      "  (0, 130669)\t0.15261260887146255\n",
      "  (0, 74519)\t0.2572541275751765\n",
      "  :\t:\n",
      "  (209526, 4)\t122.0\n",
      "  (209526, 5)\t9.0\n",
      "  (209526, 6)\t19.0\n",
      "  (209526, 49961)\t0.4286941139970831\n",
      "  (209526, 15815)\t0.43451194566248263\n",
      "  (209526, 23889)\t0.46594634185952194\n",
      "  (209526, 24053)\t0.353651167389544\n",
      "  (209526, 29816)\t0.28532827909507463\n",
      "  (209526, 30338)\t0.3184167770560488\n",
      "  (209526, 42703)\t0.32006891953215866\n",
      "  (209526, 125831)\t0.39114158154124035\n",
      "  (209526, 123056)\t0.3204302215070995\n",
      "  (209526, 70766)\t0.255034874929932\n",
      "  (209526, 114152)\t0.2724255950676916\n",
      "  (209526, 78499)\t0.2993378350485392\n",
      "  (209526, 104597)\t0.27551970898246975\n",
      "  (209526, 96376)\t0.23948238506275618\n",
      "  (209526, 68481)\t0.2165551520018411\n",
      "  (209526, 124634)\t0.32702094127009657\n",
      "  (209526, 57082)\t0.24985157146240386\n",
      "  (209526, 102803)\t0.18248499993148534\n",
      "  (209526, 82722)\t0.20500578592854368\n",
      "  (209526, 120218)\t0.19122820911831023\n",
      "  (209526, 81482)\t0.1905470804800763\n",
      "  (209526, 124175)\t0.13318775775173528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change date\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "\n",
    "# word count\n",
    "df['headline_word_count'] = df['headline'].apply(lambda x: len(str(x).split()))\n",
    "df['description_word_count'] = df['short_description'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# drop extra columns\n",
    "selected_columns = ['year', 'month', 'day', 'headline_length', 'short_description_length', 'headline_word_count', 'description_word_count' ]\n",
    "new_df = df[selected_columns].copy()\n",
    "# combine\n",
    "data = hstack([csr_matrix(new_df),tfidf])\n",
    "\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
