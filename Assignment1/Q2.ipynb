{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('patient_notes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       00  000  0000  00am  00amto4  00h  00pm  01  01pack  02  ...  zexually  \\\n",
      "0       0    0     0     0        0    0     0   0       0   0  ...         0   \n",
      "1       0    0     0     0        0    0     0   0       0   0  ...         0   \n",
      "2       0    0     0     0        0    0     0   0       0   0  ...         0   \n",
      "3       0    0     0     0        0    0     0   0       0   0  ...         0   \n",
      "4       0    0     0     0        0    0     0   0       0   0  ...         0   \n",
      "...    ..  ...   ...   ...      ...  ...   ...  ..     ...  ..  ...       ...   \n",
      "42141   0    0     0     0        0    0     0   0       0   0  ...         0   \n",
      "42142   0    0     0     0        0    0     0   0       0   0  ...         0   \n",
      "42143   0    0     0     0        0    0     0   0       0   0  ...         0   \n",
      "42144   0    0     0     0        0    0     0   0       0   0  ...         0   \n",
      "42145   0    0     0     0        0    0     0   0       0   0  ...         0   \n",
      "\n",
      "       zig  ziminopril  zno  zo  zolpidem  zone  zones  zyban  zzz  \n",
      "0        0           0    0   0         0     0      0      0    0  \n",
      "1        0           0    0   0         0     0      0      0    0  \n",
      "2        0           0    0   0         0     0      0      0    0  \n",
      "3        0           0    0   0         0     0      0      0    0  \n",
      "4        0           0    0   0         0     0      0      0    0  \n",
      "...    ...         ...  ...  ..       ...   ...    ...    ...  ...  \n",
      "42141    0           0    0   0         0     0      0      0    0  \n",
      "42142    0           0    0   0         0     0      0      0    0  \n",
      "42143    0           0    0   0         0     0      0      0    0  \n",
      "42144    0           0    0   0         0     0      0      0    0  \n",
      "42145    0           0    0   0         0     0      0      0    0  \n",
      "\n",
      "[42146 rows x 44872 columns]\n"
     ]
    }
   ],
   "source": [
    "#conda install -c conda-forge scikit-learn\n",
    "#pip install -U scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the \"pn_history\" column\n",
    "dtm = vectorizer.fit_transform(df['pn_history'])\n",
    "\n",
    "# Convert the DTM to a DataFrame\n",
    "dtm_df = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the DTM DataFrame\n",
    "print(dtm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        00  000  0000  00am  00amto4  00h  00pm   01  01pack   02  ...  \\\n",
      "0      0.0  0.0   0.0   0.0      0.0  0.0   0.0  0.0     0.0  0.0  ...   \n",
      "1      0.0  0.0   0.0   0.0      0.0  0.0   0.0  0.0     0.0  0.0  ...   \n",
      "2      0.0  0.0   0.0   0.0      0.0  0.0   0.0  0.0     0.0  0.0  ...   \n",
      "3      0.0  0.0   0.0   0.0      0.0  0.0   0.0  0.0     0.0  0.0  ...   \n",
      "4      0.0  0.0   0.0   0.0      0.0  0.0   0.0  0.0     0.0  0.0  ...   \n",
      "...    ...  ...   ...   ...      ...  ...   ...  ...     ...  ...  ...   \n",
      "42141  0.0  0.0   0.0   0.0      0.0  0.0   0.0  0.0     0.0  0.0  ...   \n",
      "42142  0.0  0.0   0.0   0.0      0.0  0.0   0.0  0.0     0.0  0.0  ...   \n",
      "42143  0.0  0.0   0.0   0.0      0.0  0.0   0.0  0.0     0.0  0.0  ...   \n",
      "42144  0.0  0.0   0.0   0.0      0.0  0.0   0.0  0.0     0.0  0.0  ...   \n",
      "42145  0.0  0.0   0.0   0.0      0.0  0.0   0.0  0.0     0.0  0.0  ...   \n",
      "\n",
      "       zexually  zig  ziminopril  zno   zo  zolpidem  zone  zones  zyban  zzz  \n",
      "0           0.0  0.0         0.0  0.0  0.0       0.0   0.0    0.0    0.0  0.0  \n",
      "1           0.0  0.0         0.0  0.0  0.0       0.0   0.0    0.0    0.0  0.0  \n",
      "2           0.0  0.0         0.0  0.0  0.0       0.0   0.0    0.0    0.0  0.0  \n",
      "3           0.0  0.0         0.0  0.0  0.0       0.0   0.0    0.0    0.0  0.0  \n",
      "4           0.0  0.0         0.0  0.0  0.0       0.0   0.0    0.0    0.0  0.0  \n",
      "...         ...  ...         ...  ...  ...       ...   ...    ...    ...  ...  \n",
      "42141       0.0  0.0         0.0  0.0  0.0       0.0   0.0    0.0    0.0  0.0  \n",
      "42142       0.0  0.0         0.0  0.0  0.0       0.0   0.0    0.0    0.0  0.0  \n",
      "42143       0.0  0.0         0.0  0.0  0.0       0.0   0.0    0.0    0.0  0.0  \n",
      "42144       0.0  0.0         0.0  0.0  0.0       0.0   0.0    0.0    0.0  0.0  \n",
      "42145       0.0  0.0         0.0  0.0  0.0       0.0   0.0    0.0    0.0  0.0  \n",
      "\n",
      "[42146 rows x 44872 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create an instance of TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the \"pn_history\" column\n",
    "dtm_tfidf = vectorizer.fit_transform(df['pn_history'])\n",
    "\n",
    "# Convert the DTM to a DataFrame\n",
    "dtm_tfidf_df = pd.DataFrame(dtm_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the TF-IDF DTM DataFrame\n",
    "print(dtm_tfidf_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After studying the n-gram, I think we could try to find gram from bigger to smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   00  00 00  00 00 waking  00 00 waking early  00 14  00 14 00  00 14 00 ros  \\\n",
      "0   0      0             0                   0      0         0             0   \n",
      "1   0      0             0                   0      0         0             0   \n",
      "2   0      0             0                   0      0         0             0   \n",
      "3   0      0             0                   0      0         0             0   \n",
      "4   0      0             0                   0      0         0             0   \n",
      "\n",
      "   00 4am  00 4am excessive  00 4am excessive caffiene  ...  \\\n",
      "0       0                 0                          0  ...   \n",
      "1       0                 0                          0  ...   \n",
      "2       0                 0                          0  ...   \n",
      "3       0                 0                          0  ...   \n",
      "4       0                 0                          0  ...   \n",
      "\n",
      "   zones ans radiate  zones ans radiate pain  zyban  zyban ndka  \\\n",
      "0                  0                       0      0           0   \n",
      "1                  0                       0      0           0   \n",
      "2                  0                       0      0           0   \n",
      "3                  0                       0      0           0   \n",
      "4                  0                       0      0           0   \n",
      "\n",
      "   zyban ndka fh  zyban ndka fh father  zzz  zzz patient  zzz patient lost  \\\n",
      "0              0                     0    0            0                 0   \n",
      "1              0                     0    0            0                 0   \n",
      "2              0                     0    0            0                 0   \n",
      "3              0                     0    0            0                 0   \n",
      "4              0                     0    0            0                 0   \n",
      "\n",
      "   zzz patient lost son  \n",
      "0                     0  \n",
      "1                     0  \n",
      "2                     0  \n",
      "3                     0  \n",
      "4                     0  \n",
      "\n",
      "[5 rows x 4509521 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Load your CSV file\n",
    "# Assuming the CSV has a column 'patient_notes' with the text data\n",
    "patient_notes = df['pn_history'].astype(str)\n",
    "\n",
    "# Optional: Download NLTK stopwords\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 4), stop_words=stopwords.words('english'))\n",
    "\n",
    "# Fit and transform the patient notes\n",
    "X = vectorizer.fit_transform(patient_notes)\n",
    "\n",
    "# Convert to DataFrame for better readability (optional)\n",
    "dtm = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Now dtm is your document-term matrix with unigrams, bigrams, trigrams, and 4-grams\n",
    "print(dtm.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS6120",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
