{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('yelp_review_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 650000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n",
      "{'label': [4, 1, 3, 3, 0], 'text': [\"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\", \"Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\", \"Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\", 'Got a letter in the mail last week that said Dr. Goldberg is moving to Arizona to take a new position there in June.  He will be missed very much.  \\\\n\\\\nI think finding a new doctor in NYC that you actually like might almost be as awful as trying to find a date!', \"I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.\"]}\n",
      "   label                                               text\n",
      "0      4  dr. goldberg offers everything i look for in a...\n",
      "1      1  Unfortunately, the frustration of being Dr. Go...\n",
      "2      3  Been going to Dr. Goldberg for over 10 years. ...\n",
      "3      3  Got a letter in the mail last week that said D...\n",
      "4      0  I don't know what Dr. Goldberg was like before...\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset['train'][:5])\n",
    "df = dataset['train'].to_pandas()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 556/556 [00:00<00:00, 32.5kB/s]\n",
      "vocab.txt: 100%|██████████| 872k/872k [00:00<00:00, 4.33MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.56M/2.56M [00:00<00:00, 28.8MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 53.4kB/s]\n",
      "config.json: 100%|██████████| 1.23k/1.23k [00:00<00:00, 655kB/s]\n",
      "/Users/caoyun/miniconda3/envs/ml-env/lib/python3.8/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "pytorch_model.bin: 100%|██████████| 670M/670M [00:29<00:00, 22.7MB/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a sentiment analysis pipeline using the specified model\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, truncation=True)\n",
    "\n",
    "sample = df.head(1000)\n",
    "results = sentiment_pipeline(sample['text'].tolist())\n",
    "# max_length = 512  # This is the typical max length for transformer models\n",
    "\n",
    "# Apply the sentiment analysis pipeline to truncated text\n",
    "# results = [sentiment_pipeline(text[:max_length]) for text in sample['text']]\n",
    "\n",
    "# Display the results\n",
    "# for text, prediction in zip(sample['text'], results):\n",
    "#     print(f\"Text: {text}\\nScore: {prediction[0]['label']}, Sentiment analysis: {prediction[0]['score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n",
    "\n",
    "LiYuan_pipeline = pipeline(model=model, tokenizer=tokenizer, task=\"sentiment-analysis\")\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "LiYuan_output = []\n",
    "\n",
    "# Iterate over the Yelp reviews\n",
    "for review in dataset['train']['text']:\n",
    "    # Encode the review\n",
    "    encoded_review = tokenizer.encode(review)\n",
    "\n",
    "    # Check if the encoded review needs to be truncated\n",
    "    if len(encoded_review) > 500:\n",
    "        # Truncate the encoded review to the first 512 tokens\n",
    "        encoded_review = encoded_review[:500]\n",
    "\n",
    "    # Perform sentiment analysis and store the output\n",
    "    LiYuan_output.append(LiYuan_pipeline(tokenizer.decode(encoded_review)))\n",
    "\n",
    "import pandas as pd\n",
    "# convert the output to a dataframe including the text\n",
    "df = pd.DataFrame(LiYuan_output)\n",
    "df[\"text\"] = dataset['train']['text']\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# If a GPU is available, move the model to the GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\").to(device)\n",
    "\n",
    "LiYuan_pipeline = pipeline(model=model, tokenizer=tokenizer, task=\"sentiment-analysis\", device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "LiYuan_output = []\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Create a DataLoader for parallelizing the data loading\n",
    "data_loader = DataLoader(dataset['train']['text'], batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# Iterate over the Yelp reviews in batches\n",
    "for batch_reviews in data_loader:\n",
    "    # Iterate over the Yelp reviews\n",
    "    for review in batch_reviews:\n",
    "        # Encode the review\n",
    "        encoded_review = tokenizer.encode(review)\n",
    "\n",
    "        # Check if the encoded review needs to be truncated\n",
    "        if len(encoded_review) > 500:\n",
    "            # Truncate the encoded review to the first 512 tokens\n",
    "            encoded_review = encoded_review[:500]\n",
    "\n",
    "        # Perform sentiment analysis and store the output\n",
    "        LiYuan_output.append(LiYuan_pipeline(tokenizer.decode(encoded_review)))\n",
    "    # # Truncate the reviews to the first 500 tokens\n",
    "    # truncated_reviews = [review[:500] for review in batch_reviews]\n",
    "\n",
    "    # # Perform sentiment analysis and store the output\n",
    "    # LiYuan_output.extend(LiYuan_pipeline(truncated_reviews))\n",
    "\n",
    "import pandas as pd\n",
    "# convert the output to a dataframe including the text\n",
    "df = pd.DataFrame(LiYuan_output)\n",
    "df[\"text\"] = dataset['train']['text']\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Create the model pipeline\n",
    "model_pipeline = pipeline(model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Yelp reviews\n",
    "yelp_reviews = dataset['train']['text']\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "model_output = []\n",
    "\n",
    "# Iterate over the Yelp reviews\n",
    "for review in yelp_reviews:\n",
    "    # Check if the review needs to be truncated\n",
    "    if len(tokenizer.encode(review)) > 512:\n",
    "        # Truncate the review to the first 512 tokens\n",
    "        review = tokenizer.decode(tokenizer.encode(review)[:512])\n",
    "\n",
    "    # Perform sentiment analysis and store the output\n",
    "    model_output.append(model_pipeline(review))\n",
    "\n",
    "# Convert the output to a dataframe including the text\n",
    "df = pd.DataFrame(model_output)\n",
    "df[\"text\"] = yelp_reviews\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Import pipeline\n",
    "# --------------------\n",
    "from transformers import pipeline\n",
    "\n",
    "# --------------------\n",
    "# Create the task pipeline\n",
    "# --------------------\n",
    "task_pipeline = pipeline(task=\"sentiment-analysis\")\n",
    "\n",
    "# --------------------\n",
    "# Create the model pipeline\n",
    "# --------------------\n",
    "model_pipeline = pipeline(model=\"siebert/sentiment-roberta-large-english\")\n",
    "# Yelp reviews\n",
    "yelp_reviews = dataset['train']['text']\n",
    "\n",
    "# Predict the sentiment of multiple sentences\n",
    "task_output = task_pipeline(yelp_reviews)\n",
    "model_output = model_pipeline(yelp_reviews)\n",
    "\n",
    "import pandas as pd\n",
    "# convert the output to a dataframe including the text\n",
    "df = pd.DataFrame(task_output)\n",
    "df[\"text\"] = yelp_reviews\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
