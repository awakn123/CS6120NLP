{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('yelp_review_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)\n",
    "print(dataset['train'][:5])\n",
    "df = dataset['train'].to_pandas()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n",
    "\n",
    "LiYuan_pipeline = pipeline(model=model, tokenizer=tokenizer, task=\"sentiment-analysis\")\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "LiYuan_output = []\n",
    "\n",
    "# Iterate over the Yelp reviews\n",
    "for review in dataset['train']['text']:\n",
    "    # Encode the review\n",
    "    encoded_review = tokenizer.encode(review)\n",
    "\n",
    "    # Check if the encoded review needs to be truncated\n",
    "    if len(encoded_review) > 500:\n",
    "        # Truncate the encoded review to the first 512 tokens\n",
    "        encoded_review = encoded_review[:500]\n",
    "\n",
    "    # Perform sentiment analysis and store the output\n",
    "    LiYuan_output.append(LiYuan_pipeline(tokenizer.decode(encoded_review)))\n",
    "\n",
    "import pandas as pd\n",
    "# convert the output to a dataframe including the text\n",
    "df = pd.DataFrame(LiYuan_output)\n",
    "df[\"text\"] = dataset['train']['text']\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# If a GPU is available, move the model to the GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\").to(device)\n",
    "\n",
    "LiYuan_pipeline = pipeline(model=model, tokenizer=tokenizer, task=\"sentiment-analysis\", device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "LiYuan_output = []\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Create a DataLoader for parallelizing the data loading\n",
    "data_loader = DataLoader(dataset['train']['text'], batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# Iterate over the Yelp reviews in batches\n",
    "for batch_reviews in data_loader:\n",
    "    # Iterate over the Yelp reviews\n",
    "    for review in batch_reviews:\n",
    "        # Encode the review\n",
    "        encoded_review = tokenizer.encode(review)\n",
    "\n",
    "        # Check if the encoded review needs to be truncated\n",
    "        if len(encoded_review) > 500:\n",
    "            # Truncate the encoded review to the first 512 tokens\n",
    "            encoded_review = encoded_review[:500]\n",
    "\n",
    "        # Perform sentiment analysis and store the output\n",
    "        LiYuan_output.append(LiYuan_pipeline(tokenizer.decode(encoded_review)))\n",
    "    # # Truncate the reviews to the first 500 tokens\n",
    "    # truncated_reviews = [review[:500] for review in batch_reviews]\n",
    "\n",
    "    # # Perform sentiment analysis and store the output\n",
    "    # LiYuan_output.extend(LiYuan_pipeline(truncated_reviews))\n",
    "\n",
    "import pandas as pd\n",
    "# convert the output to a dataframe including the text\n",
    "df = pd.DataFrame(LiYuan_output)\n",
    "df[\"text\"] = dataset['train']['text']\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Create the model pipeline\n",
    "model_pipeline = pipeline(model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Yelp reviews\n",
    "yelp_reviews = dataset['train']['text']\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "model_output = []\n",
    "\n",
    "# Iterate over the Yelp reviews\n",
    "for review in yelp_reviews:\n",
    "    # Check if the review needs to be truncated\n",
    "    if len(tokenizer.encode(review)) > 512:\n",
    "        # Truncate the review to the first 512 tokens\n",
    "        review = tokenizer.decode(tokenizer.encode(review)[:512])\n",
    "\n",
    "    # Perform sentiment analysis and store the output\n",
    "    model_output.append(model_pipeline(review))\n",
    "\n",
    "# Convert the output to a dataframe including the text\n",
    "df = pd.DataFrame(model_output)\n",
    "df[\"text\"] = yelp_reviews\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Import pipeline\n",
    "# --------------------\n",
    "from transformers import pipeline\n",
    "\n",
    "# --------------------\n",
    "# Create the task pipeline\n",
    "# --------------------\n",
    "task_pipeline = pipeline(task=\"sentiment-analysis\")\n",
    "\n",
    "# --------------------\n",
    "# Create the model pipeline\n",
    "# --------------------\n",
    "model_pipeline = pipeline(model=\"siebert/sentiment-roberta-large-english\")\n",
    "# Yelp reviews\n",
    "yelp_reviews = dataset['train']['text']\n",
    "\n",
    "# Predict the sentiment of multiple sentences\n",
    "task_output = task_pipeline(yelp_reviews)\n",
    "model_output = model_pipeline(yelp_reviews)\n",
    "\n",
    "import pandas as pd\n",
    "# convert the output to a dataframe including the text\n",
    "df = pd.DataFrame(task_output)\n",
    "df[\"text\"] = yelp_reviews\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
