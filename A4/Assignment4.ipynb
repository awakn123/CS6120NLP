{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Data Exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/nanchen/anaconda3/lib/python3.11/site-packages (2.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (0.15.1)\n",
      "Requirement already satisfied: packaging in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: filelock in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: six in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from responses<0.19->datasets) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nanchen/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "Found cached dataset parquet (/Users/nanchen/.cache/huggingface/datasets/parquet/yelp_review_full-9c7006f5a2e02666/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b117351394114b0c9859be09b73934a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('yelp_review_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 650000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n",
      "{'label': [4, 1, 3, 3, 0], 'text': [\"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\", \"Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\", \"Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\", 'Got a letter in the mail last week that said Dr. Goldberg is moving to Arizona to take a new position there in June.  He will be missed very much.  \\\\n\\\\nI think finding a new doctor in NYC that you actually like might almost be as awful as trying to find a date!', \"I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.\"]}\n",
      "   label                                               text\n",
      "0      4  dr. goldberg offers everything i look for in a...\n",
      "1      1  Unfortunately, the frustration of being Dr. Go...\n",
      "2      3  Been going to Dr. Goldberg for over 10 years. ...\n",
      "3      3  Got a letter in the mail last week that said D...\n",
      "4      0  I don't know what Dr. Goldberg was like before...\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset['train'][:5])\n",
    "df = dataset['train'].to_pandas()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 650,000 training samples and 50,000 testing samples. Each sample has a 'label' and some 'text'. The 'label' is a number from 0 to 4 that means 1 start to 5 stars and shows how good or bad the review is. The 'text' is the review itself. The next step in the code will create a picture that shows how many samples there are for each label number, both for training and testing. This is to make sure we have a fair mix, which helps build fair and reliable machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Plot the distribution of labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.countplot(data=df, x='label')\n",
    "plt.title('Label Distribution of train data in Yelp Review Dataset')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Annotate each bar with the count of observations\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'center', xytext = (0, 10), \n",
    "                textcoords = 'offset points')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "df_test = dataset['test'].to_pandas()\n",
    "# Plot the distribution of labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.countplot(data=df_test, x='label')\n",
    "plt.title('Label Distribution of test data in Yelp Review Dataset')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Annotate each bar with the count of observations\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'center', xytext = (0, 10), \n",
    "                textcoords = 'offset points')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two images depict the label distributions in the training and test datasets, respectively. Each chart shows an equal count for all labels, which is crucial for developing unbiased machine learning models with broad applicability. This uniformity ensures that the models trained on this data can learn and evaluate effectively without preference for any particular label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created a new DataFrame based on a random sample of 1000 rows from an existing DataFrame. This new DataFrame contains three columns: ‘sentiment’, 'label' and ‘text’. The ‘sentiment’ column is determined by mapping the original labels to sentiment categories. Specifically, labels ‘0’ and ‘1’ are mapped to ‘Negative’, and labels ‘3’ and ‘4’ are mapped to ‘Positive’. Therefore, each row in the DataFrame represents a text sample, its original label and its corresponding sentiment label. In the randow sample, it flitered out rows woth label ‘2’ as one of the model I choosen does not have ‘Neutral’ sentiment predition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with label 2\n",
    "df = df[df['label'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label                                               text\n",
      "87408       1  Although I've dined at Lombardino's before and...\n",
      "431412      0  This review is basically for AT & T in general...\n",
      "467836      0  Gestern hatte ich wieder so einen B\\u00f6ckele...\n",
      "637767      4  Have been to this restaurant several times now...\n",
      "209964      4  Solid 5 stars.  I love P.F. Chang's.  I had a ...\n",
      "        label                                               text\n",
      "647041      4  Great place. Perfect for lunch or dinner or ju...\n",
      "31583       1  I came into the restaurant a few days ago and ...\n",
      "478076      0  Done, gone, repossessed!  How you have a semi-...\n",
      "204086      1  This place is okay, not worth the 2.50 per cup...\n",
      "600552      0  My fianc\\u00e9 and I really don't like Olive G...\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 1000 rows from the DataFrame\n",
    "random_sample = df.sample(n=1000, random_state=1)\n",
    "# Print the first five rows\n",
    "print(random_sample.head())\n",
    "# Print the last five rows\n",
    "print(random_sample.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index sentiment  label                                               text\n",
      "0   87408  Negative      1  Although I've dined at Lombardino's before and...\n",
      "1  431412  Negative      0  This review is basically for AT & T in general...\n",
      "2  467836  Negative      0  Gestern hatte ich wieder so einen B\\u00f6ckele...\n",
      "3  637767  Positive      4  Have been to this restaurant several times now...\n",
      "4  209964  Positive      4  Solid 5 stars.  I love P.F. Chang's.  I had a ...\n",
      "      index sentiment  label  \\\n",
      "995  647041  Positive      4   \n",
      "996   31583  Negative      1   \n",
      "997  478076  Negative      0   \n",
      "998  204086  Negative      1   \n",
      "999  600552  Negative      0   \n",
      "\n",
      "                                                  text  \n",
      "995  Great place. Perfect for lunch or dinner or ju...  \n",
      "996  I came into the restaurant a few days ago and ...  \n",
      "997  Done, gone, repossessed!  How you have a semi-...  \n",
      "998  This place is okay, not worth the 2.50 per cup...  \n",
      "999  My fianc\\u00e9 and I really don't like Olive G...  \n"
     ]
    }
   ],
   "source": [
    "# Define a function to map the label numbers to sentiment labels\n",
    "def map_label(label):\n",
    "    if label in [0, 1]:\n",
    "        return \"Negative\"\n",
    "    elif label == 2:\n",
    "        return \"Neutral\"\n",
    "    else:  # 3 and 4\n",
    "        return \"Positive\"\n",
    "\n",
    "# Apply the function to the 'label' column to create a new 'sentiment' column\n",
    "random_sample['sentiment'] = random_sample['label'].apply(map_label)\n",
    "\n",
    "# Create a new DataFrame with only 'sentiment' and 'text' columns\n",
    "new_df = random_sample[['sentiment', 'label', 'text' ]].copy()\n",
    "\n",
    "# Reset the index of the new DataFrame, but keep the old index\n",
    "new_df.reset_index(inplace=True)\n",
    "\n",
    "# Print the first five rows\n",
    "print(new_df.head())\n",
    "\n",
    "# Print the last five rows\n",
    "print(new_df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, i choose three models: \"cardiffnlp/twitter-roberta-base-sentiment-latest\", \"LiYuan/amazon-review-sentiment-analysis\" and \"distilbert-base-uncased-finetuned-sst-2-english\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"cardiffnlp/twitter-roberta-base-sentiment-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     negative  neutral  positive  \\\n",
      "0      0.6432   0.3035    0.0533   \n",
      "1      0.4116   0.5362    0.0522   \n",
      "2      0.0704   0.7087    0.2209   \n",
      "3      0.0034   0.0100    0.9865   \n",
      "4      0.0884   0.1731    0.7385   \n",
      "..        ...      ...       ...   \n",
      "995    0.0027   0.0128    0.9845   \n",
      "996    0.8955   0.0915    0.0130   \n",
      "997    0.8828   0.1080    0.0092   \n",
      "998    0.8441   0.1386    0.0173   \n",
      "999    0.7318   0.2247    0.0435   \n",
      "\n",
      "                                                  text  \n",
      "0    Although I've dined at Lombardino's before and...  \n",
      "1    This review is basically for AT & T in general...  \n",
      "2    Gestern hatte ich wieder so einen B\\u00f6ckele...  \n",
      "3    Have been to this restaurant several times now...  \n",
      "4    Solid 5 stars.  I love P.F. Chang's.  I had a ...  \n",
      "..                                                 ...  \n",
      "995  Great place. Perfect for lunch or dinner or ju...  \n",
      "996  I came into the restaurant a few days ago and ...  \n",
      "997  Done, gone, repossessed!  How you have a semi-...  \n",
      "998  This place is okay, not worth the 2.50 per cup...  \n",
      "999  My fianc\\u00e9 and I really don't like Olive G...  \n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "results = []\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "#model.save_pretrained(MODEL)\n",
    "# Iterate over the Yelp reviews in batches\n",
    "for review in random_sample['text']:\n",
    "\n",
    "    # Tokenize the batch of reviews\n",
    "    encoded_input = tokenizer(review, truncation=True, max_length=500, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    result = {}\n",
    "    for i in range(scores.shape[0]):\n",
    "        l = config.id2label[ranking[i]]\n",
    "        s = scores[ranking[i]]\n",
    "        result[l] = np.round(float(s), 4)\n",
    "    result[\"text\"] = review\n",
    "    results.append(result)\n",
    "\n",
    "# Convert the output to a dataframe including the text\n",
    "cardiffnlp_df = pd.DataFrame(results)\n",
    "print(cardiffnlp_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created a new DataFrame with three columns: ‘label’, ‘score’, and ‘text’. For each row, the ‘label’ column is determined by the sentiment (positive, neutral, or negative) that has the highest score. The ‘score’ column contains the highest score itself, and the ‘text’ column contains the corresponding review text. In other words, for each review, the DataFrame stores the most likely sentiment, the confidence score of that sentiment, and the review text itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label   score                                               text\n",
      "0    negative  0.6432  Although I've dined at Lombardino's before and...\n",
      "1     neutral  0.5362  This review is basically for AT & T in general...\n",
      "2     neutral  0.7087  Gestern hatte ich wieder so einen B\\u00f6ckele...\n",
      "3    positive  0.9865  Have been to this restaurant several times now...\n",
      "4    positive  0.7385  Solid 5 stars.  I love P.F. Chang's.  I had a ...\n",
      "..        ...     ...                                                ...\n",
      "995  positive  0.9845  Great place. Perfect for lunch or dinner or ju...\n",
      "996  negative  0.8955  I came into the restaurant a few days ago and ...\n",
      "997  negative  0.8828  Done, gone, repossessed!  How you have a semi-...\n",
      "998  negative  0.8441  This place is okay, not worth the 2.50 per cup...\n",
      "999  negative  0.7318  My fianc\\u00e9 and I really don't like Olive G...\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the outputs\n",
    "new_results = []\n",
    "\n",
    "# Iterate over the results\n",
    "for result in results:\n",
    "    # Create a new dictionary that only contains the sentiment scores\n",
    "    scores = {k: v for k, v in result.items() if k != 'text'}\n",
    "    # Get the label with the maximum score\n",
    "    max_label = max(scores, key=scores.get)\n",
    "    # Get the maximum score\n",
    "    max_score = scores[max_label]\n",
    "    # Get the text\n",
    "    text = result['text']\n",
    "    # Append the new result to the new_results list\n",
    "    new_results.append({'label': max_label, 'score': max_score, 'text': text})\n",
    "\n",
    "# Convert the output to a dataframe including the text\n",
    "new_cardiffnlp_df = pd.DataFrame(new_results)\n",
    "print(new_cardiffnlp_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"LiYuan/amazon-review-sentiment-analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label     score                                               text\n",
      "0    2 stars  0.895350  Although I've dined at Lombardino's before and...\n",
      "1     1 star  0.924806  This review is basically for AT & T in general...\n",
      "2    5 stars  0.648529  Gestern hatte ich wieder so einen B\\u00f6ckele...\n",
      "3    5 stars  0.858533  Have been to this restaurant several times now...\n",
      "4    5 stars  0.850267  Solid 5 stars.  I love P.F. Chang's.  I had a ...\n",
      "..       ...       ...                                                ...\n",
      "995  5 stars  0.770085  Great place. Perfect for lunch or dinner or ju...\n",
      "996   1 star  0.552957  I came into the restaurant a few days ago and ...\n",
      "997  5 stars  0.728095  Done, gone, repossessed!  How you have a semi-...\n",
      "998  3 stars  0.825199  This place is okay, not worth the 2.50 per cup...\n",
      "999   1 star  0.369396  My fianc\\u00e9 and I really don't like Olive G...\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "results = []\n",
    "\n",
    "for review in random_sample['text']:\n",
    "    # Tokenize the batch of reviews\n",
    "    encoded_input = tokenizer(review, truncation=True, max_length=500, padding=True, return_tensors=\"pt\")\n",
    "    result = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**encoded_input).logits\n",
    "\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    predicted_class_label = model.config.id2label[predicted_class_id]\n",
    "\n",
    "    # Apply softmax to the logits\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "    # Get the probability of the predicted class\n",
    "    predicted_class_probability = probabilities[0, predicted_class_id].item()\n",
    "\n",
    "    # Store the review, predicted class label, and probability in the result dictionary\n",
    "    result[\"label\"] = predicted_class_label\n",
    "    result[\"score\"] = predicted_class_probability\n",
    "    result[\"text\"] = review\n",
    "\n",
    "    # Append the result dictionary to the results list\n",
    "    results.append(result)\n",
    "\n",
    "# Convert the output to a dataframe including the text\n",
    "LiYuan_df = pd.DataFrame(results)\n",
    "print(LiYuan_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created a new DataFrame with three columns: ‘label’, ‘score’, and ‘text’. The ‘label’ column is determined by the sentiment corresponding to the star rating of each review. For instance, reviews with a rating of ‘5 stars’ or ‘4 stars’ are labeled as ‘Positive’, reviews with a ‘3 stars’ rating are labeled as ‘Neutral’, and those with ‘2 stars’ or ‘1 star’ are labeled as ‘Negative’. The ‘score’ column contains the corresponding sentiment score, and the ‘text’ column contains the review text. Therefore, each row in the DataFrame represents a review, its sentiment label, and the sentiment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label     score                                               text\n",
      "0    Negative  0.895350  Although I've dined at Lombardino's before and...\n",
      "1    Negative  0.924806  This review is basically for AT & T in general...\n",
      "2    Positive  0.648529  Gestern hatte ich wieder so einen B\\u00f6ckele...\n",
      "3    Positive  0.858533  Have been to this restaurant several times now...\n",
      "4    Positive  0.850267  Solid 5 stars.  I love P.F. Chang's.  I had a ...\n",
      "..        ...       ...                                                ...\n",
      "995  Positive  0.770085  Great place. Perfect for lunch or dinner or ju...\n",
      "996  Negative  0.552957  I came into the restaurant a few days ago and ...\n",
      "997  Positive  0.728095  Done, gone, repossessed!  How you have a semi-...\n",
      "998   Neutral  0.825199  This place is okay, not worth the 2.50 per cup...\n",
      "999  Negative  0.369396  My fianc\\u00e9 and I really don't like Olive G...\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define a function to map star ratings to sentiment labels\n",
    "def map_label(label):\n",
    "    if label in [\"5 stars\", \"4 stars\"]:\n",
    "        return \"Positive\"\n",
    "    elif label == \"3 stars\":\n",
    "        return \"Neutral\"\n",
    "    else:  # \"2 stars\" and \"1 star\"\n",
    "        return \"Negative\"\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "new_results = []\n",
    "\n",
    "for result in results:\n",
    "    # Map the star rating to a sentiment label\n",
    "    new_label = map_label(result[\"label\"])\n",
    "    # Store the review, new sentiment label, and probability in the result dictionary\n",
    "    new_result = {\"label\": new_label, \"score\": result[\"score\"], \"text\": result[\"text\"]}\n",
    "    # Append the new result dictionary to the new_results list\n",
    "    new_results.append(new_result)\n",
    "\n",
    "# Convert the output to a dataframe including the text\n",
    "new_LiYuan_df = pd.DataFrame(new_results)\n",
    "print(new_LiYuan_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"distilbert-base-uncased-finetuned-sst-2-english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label     score                                               text\n",
      "0    NEGATIVE  0.999523  Although I've dined at Lombardino's before and...\n",
      "1    NEGATIVE  0.999587  This review is basically for AT & T in general...\n",
      "2    NEGATIVE  0.995537  Gestern hatte ich wieder so einen B\\u00f6ckele...\n",
      "3    POSITIVE  0.999798  Have been to this restaurant several times now...\n",
      "4    POSITIVE  0.983273  Solid 5 stars.  I love P.F. Chang's.  I had a ...\n",
      "..        ...       ...                                                ...\n",
      "995  POSITIVE  0.999824  Great place. Perfect for lunch or dinner or ju...\n",
      "996  NEGATIVE  0.997701  I came into the restaurant a few days ago and ...\n",
      "997  NEGATIVE  0.999292  Done, gone, repossessed!  How you have a semi-...\n",
      "998  NEGATIVE  0.998770  This place is okay, not worth the 2.50 per cup...\n",
      "999  NEGATIVE  0.978287  My fianc\\u00e9 and I really don't like Olive G...\n",
      "\n",
      "[1000 rows x 3 columns]\n",
      "label\n",
      "NEGATIVE    522\n",
      "POSITIVE    478\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Initialize an empty list to store the outputs\n",
    "results = []\n",
    "\n",
    "for review in random_sample['text']:\n",
    "    # Tokenize the batch of reviews\n",
    "    encoded_input = tokenizer(review, truncation=True, max_length=500, padding=True, return_tensors=\"pt\")\n",
    "    result = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**encoded_input).logits\n",
    "\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    predicted_class_label = model.config.id2label[predicted_class_id]\n",
    "\n",
    "    # Apply softmax to the logits\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "    # Get the probability of the predicted class\n",
    "    predicted_class_probability = probabilities[0, predicted_class_id].item()\n",
    "\n",
    "    # Store the review, predicted class label, and probability in the result dictionary\n",
    "    result[\"label\"] = predicted_class_label\n",
    "    result[\"score\"] = predicted_class_probability\n",
    "    result[\"text\"] = review\n",
    "\n",
    "    # Append the result dictionary to the results list\n",
    "    results.append(result)\n",
    "\n",
    "# Convert the output to a dataframe including the text\n",
    "distilbert_df = pd.DataFrame(results)\n",
    "print(distilbert_df)\n",
    "print(distilbert_df['label'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the overall sentiment distribution and provide insights based on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I computed the percentage of incorrect predictions made by three sentiment analysis models (new_cardiffnlp_df, new_LiYuan_df, distilbert_df) for each sentiment label (0, 1, 3, 4) in the new_df dataset. I then visualized these percentages using a histogram. The x-axis of the histogram represents the sentiment labels, while the y-axis represents the percentage of incorrect predictions. Each sentiment label on the x-axis has three corresponding bars on the histogram, each representing the percentage of incorrect predictions made by one of the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect count for each model:\n",
      "\n",
      "   Label  cardiffnlp_model  LiYuan_model  distilbert_model\n",
      "0      0                50            38                 5\n",
      "1      1               100           113                29\n",
      "2      3                31            10                41\n",
      "3      4                15             3                19\n",
      "4  Total               196           164                94\n",
      "\n",
      "Incorrect precentage for each model:\n",
      "\n",
      "   Label  cardiffnlp_model  LiYuan_model  distilbert_model\n",
      "0      0         25.510204     23.170732          5.319149\n",
      "1      1         51.020408     68.902439         30.851064\n",
      "2      3         15.816327      6.097561         43.617021\n",
      "3      4          7.653061      1.829268         20.212766\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# These are the true sentiments of the reviews\n",
    "true_sentiments = new_df['sentiment'].str.lower()\n",
    "\n",
    "# These are the labels predicted by the three models\n",
    "predicted_labels_model1 = new_cardiffnlp_df['label'].str.lower()\n",
    "predicted_labels_model2 = new_LiYuan_df['label'].str.lower()\n",
    "predicted_labels_model3 = distilbert_df['label'].str.lower()\n",
    "\n",
    "# Initialize counters for each model\n",
    "incorrect_counts_model1 = {0: 0, 1: 0, 3: 0, 4: 0}\n",
    "incorrect_counts_model2 = {0: 0, 1: 0, 3: 0, 4: 0}\n",
    "incorrect_counts_model3 = {0: 0, 1: 0, 3: 0, 4: 0}\n",
    "\n",
    "# Iterate over the reviews\n",
    "for i, true_sentiment in enumerate(true_sentiments):\n",
    "    if true_sentiment != 'neutral':\n",
    "        # Get the predictions of the three models\n",
    "        pred1, pred2, pred3 = predicted_labels_model1[i], predicted_labels_model2[i], predicted_labels_model3[i]\n",
    "        # If any of the predictions is incorrect\n",
    "        if true_sentiment != pred1:\n",
    "            incorrect_counts_model1[new_df['label'][i]] += 1\n",
    "        if true_sentiment != pred2:\n",
    "            incorrect_counts_model2[new_df['label'][i]] += 1\n",
    "        if true_sentiment != pred3:\n",
    "            incorrect_counts_model3[new_df['label'][i]] += 1\n",
    "\n",
    "# Calculate total number of incorrent labels for each model\n",
    "total_incorrect_counts_model1 = sum(incorrect_counts_model1.values())\n",
    "total_incorrect_counts_model2 = sum(incorrect_counts_model2.values())\n",
    "total_incorrect_counts_model3 = sum(incorrect_counts_model3.values())\n",
    "\n",
    "# Calculate the percentage of incorrect predictions for each model\n",
    "percentage_incorrect_model1 = {k: (v / total_incorrect_counts_model1) * 100 for k, v in incorrect_counts_model1.items()}\n",
    "percentage_incorrect_model2 = {k: (v / total_incorrect_counts_model2) * 100 for k, v in incorrect_counts_model2.items()}\n",
    "percentage_incorrect_model3 = {k: (v / total_incorrect_counts_model3) * 100 for k, v in incorrect_counts_model3.items()}\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Label': [0, 1, 3, 4],\n",
    "    'cardiffnlp_model': [incorrect_counts_model1[i] for i in [0, 1, 3, 4]],\n",
    "    'LiYuan_model': [incorrect_counts_model2[i] for i in [0, 1, 3, 4]],\n",
    "    'distilbert_model': [incorrect_counts_model3[i] for i in [0, 1, 3, 4]]\n",
    "})\n",
    "\n",
    "# Create a new DataFrame with the total percentages\n",
    "total_df = pd.DataFrame({\n",
    "    'Label': ['Total'],\n",
    "    'cardiffnlp_model': [total_incorrect_counts_model1],\n",
    "    'LiYuan_model': [total_incorrect_counts_model2],\n",
    "    'distilbert_model': [total_incorrect_counts_model3]\n",
    "})\n",
    "\n",
    "# Append the new DataFrame to the original DataFrame\n",
    "results_df1 = pd.concat([results_df, total_df], ignore_index=True)\n",
    "print(\"Incorrect count for each model:\")\n",
    "print()\n",
    "print(results_df1)\n",
    "print()\n",
    "\n",
    "percentage_incorrect_results_df = pd.DataFrame({\n",
    "    'Label': [0, 1, 3, 4],\n",
    "    'cardiffnlp_model': [percentage_incorrect_model1[i] for i in [0, 1, 3, 4]],\n",
    "    'LiYuan_model': [percentage_incorrect_model2[i] for i in [0, 1, 3, 4]],\n",
    "    'distilbert_model': [percentage_incorrect_model3[i] for i in [0, 1, 3, 4]]\n",
    "})\n",
    "print(\"Incorrect precentage for each model:\")\n",
    "print()\n",
    "print(percentage_incorrect_results_df)\n",
    "\n",
    "\n",
    "# Plot a histogram of the results\n",
    "ax = percentage_incorrect_results_df.plot(x='Label', y=['cardiffnlp_model', 'LiYuan_model', 'distilbert_model'], kind='bar')\n",
    "plt.ylabel('Percentage of Incorrect Predictions')\n",
    "plt.title('Comparison of Model Performance')\n",
    "\n",
    "# Add data labels above each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.1f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 10), \n",
    "                   textcoords = 'offset points')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sentiment Distribution: \n",
    "\n",
    "    The sentiment labels are distributed across four categories: 0, 1, 3, and 4. In our dataset, labels ‘0’ and ‘1’ are mapped to ‘Negative’, and labels ‘3’ and ‘4’ are mapped to ‘Positive’. This suggests that the dataset includes reviews with both positive and negative sentiments.\n",
    "\n",
    "2. Model Performance: \n",
    "\n",
    "    The three models (new_cardiffnlp_df, new_LiYuan_df, distilbert_df) have varying levels of performance. The distilbert_df model appears to have the lowest overall percentage of incorrect predictions (9.4%), suggesting that it is the most accurate of the three models. The new_cardiffnlp_df and new_LiYuan_df models have higher overall percentages of incorrect predictions (19.6% and 16.4% respectively), indicating that they are less accurate.\n",
    "\n",
    "3. Types of Mistakes: \n",
    "\n",
    "    new_cardiffnlp_df Model: This model has the highest percentage of incorrect predictions for sentiment label ‘1’ (51%), suggesting that it struggles the most with correctly predicting this sentiment. It performs best with sentiment label ‘4’ (7.7% incorrect predictions).\n",
    "\n",
    "    new_LiYuan_df Model: This model also has the highest percentage of incorrect predictions for sentiment label ‘1’ (68.9%), indicating a similar struggle with this sentiment. It performs best with sentiment label ‘4’ (1.8% incorrect predictions).\n",
    "\n",
    "    distilbert_df Model: This model has the highest percentage of incorrect predictions for sentiment label ‘3’ (43.6%), which is different from the other two models. It performs best with sentiment label ‘0’ (5.3% incorrect predictions).\n",
    "\n",
    "In a tournament of the three models, distilbert_df would be the winner due to its lower overall percentage of incorrect predictions. The new_cardiffnlp_df and new_LiYuan_df models seem to struggle the most with predicting negative sentiments, but  performs better regarding positive sentiments. The distilbert_df model performs better regarding negative sentiments but struggle more with predicting positive sentiments.The result also suggests that the new_cardiffnlp_df and new_LiYuan_df models might have difficulty distinguishing between certain sentiments, particularly between ‘0’ and '1' sentiment labels, and for distilbert_df model, it is between ‘1’ and '3' sentiment labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall sentiment distribution:\n",
      "sentiment\n",
      "positive    504\n",
      "negative    496\n",
      "Name: count, dtype: int64\n",
      "cardiffnlp sentiment distribution:\n",
      "label\n",
      "positive    528\n",
      "negative    361\n",
      "neutral     111\n",
      "Name: count, dtype: int64\n",
      "LiYuan sentiment distribution:\n",
      "label\n",
      "positive    561\n",
      "negative    347\n",
      "neutral      92\n",
      "Name: count, dtype: int64\n",
      "distilbert sentiment distribution:\n",
      "label\n",
      "negative    522\n",
      "positive    478\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Model: cardiffnlp\n",
      "Confusion Matrix:\n",
      "[[458  15  31]\n",
      " [ 70 346  80]\n",
      " [  0   0   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.87      0.91      0.89       504\n",
      "    negative       0.96      0.70      0.81       496\n",
      "     neutral       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.61      0.54      0.57      1000\n",
      "weighted avg       0.91      0.80      0.85      1000\n",
      "\n",
      "\n",
      "Model: LiYuan\n",
      "Confusion Matrix:\n",
      "[[491   2  11]\n",
      " [ 70 345  81]\n",
      " [  0   0   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.88      0.97      0.92       504\n",
      "    negative       0.99      0.70      0.82       496\n",
      "     neutral       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.62      0.56      0.58      1000\n",
      "weighted avg       0.93      0.84      0.87      1000\n",
      "\n",
      "\n",
      "Model: distilbert\n",
      "Confusion Matrix:\n",
      "[[444  60   0]\n",
      " [ 34 462   0]\n",
      " [  0   0   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.93      0.88      0.90       504\n",
      "    negative       0.89      0.93      0.91       496\n",
      "     neutral       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1000\n",
      "   macro avg       0.60      0.60      0.60      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nanchen/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Analyze the overall sentiment distribution\n",
    "print(\"Overall sentiment distribution:\")\n",
    "print(true_sentiments.value_counts())\n",
    "\n",
    "print(\"cardiffnlp sentiment distribution:\")\n",
    "print(predicted_labels_model1.value_counts())\n",
    "\n",
    "print(\"LiYuan sentiment distribution:\")\n",
    "print(predicted_labels_model2.value_counts())\n",
    "\n",
    "print(\"distilbert sentiment distribution:\")\n",
    "print(predicted_labels_model3.value_counts())\n",
    "\n",
    "# Perform a tournament of 3 models and compare results\n",
    "models = { \"cardiffnlp\": predicted_labels_model1, \"LiYuan\": predicted_labels_model2, \"distilbert\": predicted_labels_model3}\n",
    "for model_name, predicted_labels in models.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(true_sentiments, predicted_labels, labels=[\"positive\", \"negative\", \"neutral\" ]))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(true_sentiments, predicted_labels, labels=[\"positive\", \"negative\", \"neutral\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output, here's an analysis of the sentiment distribution and model performance:\n",
    "\n",
    "1. Sentiment Distribution:\n",
    "    \n",
    "    The overall sentiment distribution in the dataset is almost balanced with a slight skew towards positive reviews.\n",
    "\n",
    "    All three models, cardiffnlp, LiYuan, and distilbert, have predicted more positive sentiments than negative. This could be due to the models being more biased towards predicting positive sentiments, or it could be a reflection of the data they were trained on.\n",
    "\n",
    "2. Model Performance:\n",
    "\n",
    "    cardiffnlp: This model has a high precision for both positive and negative sentiments, indicating that when it predicts a review to be positive or negative, it is usually correct. However, its recall for negative sentiments is relatively low, meaning it often fails to identify negative reviews correctly. It seems to misclassify negative reviews as either positive or neutral.\n",
    "\n",
    "    LiYuan: This model has a very high precision for negative sentiments and a high recall for positive sentiments. This means it is very accurate when it predicts a review to be negative and is good at identifying positive reviews. However, like cardiffnlp, it also struggles with identifying negative reviews correctly, often misclassifying them as positive or neutral.\n",
    "\n",
    "    distilbert: This model has a balanced precision and recall for both positive and negative sentiments, indicating it is good at predicting and identifying both positive and negative reviews. However, it seems to misclassify some positive reviews as negative, as indicated by the lower recall for positive sentiments.\n",
    "\n",
    "3. Types of Mistakes:\n",
    "\n",
    "    cardiffnlp: This model seems to struggle with false negatives for the negative class, i.e., predicting negative sentiments as positive or neutral.\n",
    "\n",
    "    LiYuan: This model also struggles with false negatives for the negative class. It often predicts negative sentiments as positive or neutral.\n",
    "\n",
    "    distilbert: This model's main type of mistake is false negatives for the positive class, i.e., predicting positive sentiments as negative.\n",
    "\n",
    "In conclusion, while all three models have their strengths and weaknesses, distilbert seems to perform the best overall in terms of balanced precision and recall for both positive and negative sentiments. \n",
    "\n",
    "Then i will choose 5 incorrect prediction samples for each model and analyze the types of mistakes each model made regarding the reviewing texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LiYuan model:\n",
      "Index: 0\n",
      "True Label: negative\n",
      "Predicted Label: positive\n",
      "Text: I used to like Paradise Bakery a lot more than I do now. They've changed their menu a bunch, and while I appreciate a menu that isn't stagnant, I found myself just staring at their chalk boards unable to find something that sounded appealing. \\n\\nI ended up selecting their avocado Cobb salad and it came with like three chunks of avocado. My full size salad and a medium sized mediocre iced coffee drink ran me almost $15 after tax.\\n\\nNot impressed.\n",
      "\n",
      "Index: 1\n",
      "True Label: negative\n",
      "Predicted Label: positive\n",
      "Text: The only thing I liked about this buffet was the price. Other than that, it was not as good as I thought.\n",
      "\n",
      "Index: 2\n",
      "True Label: negative\n",
      "Predicted Label: positive\n",
      "Text: Visited this Primanti Bros. Last Saturday night when I came to town for a Steelers game. Had never been here before and tried the steak sandwhich. It was not that good for the #2 sandwich in town (I'm assuming). I was told by a cousin who has lived in town for 5 years that it was overrated and found this to be true with the quality of food. \\n\\nOn a positive note the staff was amazing and so was the atmosphere.\n",
      "\n",
      "Index: 3\n",
      "True Label: negative\n",
      "Predicted Label: positive\n",
      "Text: I remember my first experience at a diner: Art Deco-inspired architecture, narrow and long floorplan, jukeboxes, neon signs, quick service, and extremely tasty pancakes with chocolate syrup! Granted I was only 7 or 8 years old then, but I can recall everything (how can I forget the taste of those pancakes?!). Since then, I've been to quite a few diners, including diner-restaurants (i.e. faux diners). I would go particularly on the morning after a night of partying and/or drinking, when I'm feeling too lazy or hung over to cook something decent without burning myself and my kitchen. On these mornings, I would typically order pancakes or omelettes with a side (usually hash browns) and coffee. Honestly, I've never eaten anything other than these breakfast staples at a diner.\\n\\nMy friends and I arranged to have a late brunch one day at Ritters Diner. Now, I didn't have much to eat the night before, so I couldn't wait until we met to have something to eat. So, I came to the diner having already eaten a light breakfast. A quick observation of the diner made me realize that this isn't a traditional diner; instead, it seemed more like a diner-restaurant. Oh well, there was still the service and the food to worry about. We sat down at a booth in the large room in the back of the restaurant. The waitress greeted us and took our drink orders immediately: two cups of coffee and two glasses of water. Several minutes later, we got our coffee and water, but weren't ready to order just yet. We spent several more minutes deciding, and when we were ready, we placed our menus in a neat stack in the center of the table to show that we were ready to order. We waited...and waited...and waited some\n",
      "\n",
      "Index: 4\n",
      "True Label: negative\n",
      "Predicted Label: positive\n",
      "Text: I never review places, but I felt I had to say something about the SLS. My family stayed here for one night on our family vacation. To start, our room smelled like a combination of wet dog, old dumplings and garbage. We then all went to dinner downstairs at Umami Burger, which we thought was delicious until my father, sister, and brother-in-law likely got food poisoning. Needless to say, we canceled our reservation the next day so everyone could be sick in a more peaceful environment. \\n\\nThat being said, I did enjoy their toiletries.\n",
      "\n",
      "\n",
      "cardiffnlp model:\n",
      "Index: 0\n",
      "True Label: negative\n",
      "Predicted Label: positive\n",
      "Text: Admittedly I was unable to actually eat here but my review might explain...\\n\\nWe arrived about 7pm to a pretty full restaurant, good sign that a good meal is ahead. Although there is no sign asking us to wait or seat ourselves, we wait up front to be be sure. After about 5 minutes we decided it must be seat yourself as not one person from the staff, who eyed us several times, approaches us to help. \\n\\nAs I head for one of the three empty tables, a man appears out of the kitchen and says \\\"Can I help you?\\\" \\n\\nSure I reply, we'd like a seat. He replies, \\\"Well sit up front and wait, there are no tables\\\", quickly followed by \\\"did you call ahead? Everybody knows to call ahead, we're a busy place\\\"\\n\\nIt's at that point we decide to liberate ourselves from the rudeness and eat elsewhere. I'm sorry I didn't know the Amore rules, perhaps they should post them somewhere. I'm happy they are so successful but I do draw the line at treating your customers rudely because you're busy.\n",
      "\n",
      "Index: 1\n",
      "True Label: negative\n",
      "Predicted Label: positive\n",
      "Text: It was okay. My husband & I went there last week & neither of us have any real complaints. Everything was okay... the food was mediocre, the service was fine but nothing over the top.\n",
      "\n",
      "Index: 2\n",
      "True Label: negative\n",
      "Predicted Label: positive\n",
      "Text: Bubble tease is one of those things you just have to try. \\nIt's exceedingly popular amongst students here. And for good reason.\\n\\nThe places' atmosphere is thrifty, with random furniture. It has somewhat of a hippie-feel to it. But somehow it works.\\n\\nBubble Tease has a very high novelty factor, and is definitely fun to chill out for a bit with some friends.\n",
      "\n",
      "Index: 3\n",
      "True Label: negative\n",
      "Predicted Label: positive\n",
      "Text: We only went here because they have cheap tables and they're supposed to have food and drink specials.\\n\\nPro's\\nCheap Tables roulette and craps\\nThe bartenders and other staff were busting my balls, loved it\\n\\nCon's\\nThe cocktail waitresses were pretty beat and not very nice. \\nBars that had the food and drink specials were too packed to get in\\ndrinks weren't good\\ndrinks were as expensive as on the strip\\nIt is old and dingy\\nI kept getting carded and when I asked for a wrist band security put it on so tight I lost circulation and had to take it off.\n",
      "\n",
      "Index: 4\n",
      "True Label: negative\n",
      "Predicted Label: positive\n",
      "Text: We've been back twice now since our first visit. The second time, was still pretty good. Went last Sunday, (10/16/11), and it could have been way better. We think that they have started to try to cut costs, and it's showing. Will maybe give it one more try. Maybe.\n",
      "\n",
      "\n",
      "distilbert model:\n",
      "Index: 0\n",
      "True Label: positive\n",
      "Predicted Label: negative\n",
      "Text: I love Presidential. I've used them now 4 times. All of the drivers have been great. They have always been on time. I have modified reservations with no issues. The cars were all new and clean, smelled great. The sound systems were kinda weak, especially in the 12-14 person Escalade. It sounded as if they had no rear speakers. \\n\\nI've done point to point transfers, the airport transfer, and the tour. The tour was fun, but the wasn't really a tour as much as it was a chauffeur to a few places. Luckily I know the city well enough it was not an issue. The champagne is usually warm, and its nothing fancy, but it tasted alright with ice. We had no problem killing the bottles in a few minutes, so it couldn't have been *that* bad. But like I said, its cheap champagne, its a nice touch, but shouldn't play any factor in picking Presidential over a competitor.\\n\\nI have seen some people on Yelp that have had some customer service issues, and i've seen Presidential's response and it does seem to come off a bit abrasive. Hopefully I am never on the receiving end, and a lot of it seems to be people not reading the details,etc, but I do think it could publicly be handled in a more elegant fashion from the companies side.\\n\\nFor me, I wont use any other company in Las Vegas for limo service for my future visits to this wonderful city. It sure beats a rank smelling cabby or fighting to avoid the \\\"Fast route\\\" aka the tunnel.\n",
      "\n",
      "Index: 1\n",
      "True Label: negative\n",
      "Predicted Label: positive\n",
      "Text: I will rate 1. Hotel, 2. Casino, 3. Kids venue, 4. Overall quality\\n1. Hotel rooms are okay 3.5 stars. The elevator system gets (1-generous heavy weighted star). We stay here every year and its the same thing every year. When 10:30 to 11 AM rolls around, everybody is trying to get out of the building, however the elevators are so slow that it takes 40-minutes to get down. By the time it gets to your floor they are already full. If you don't have luggage, take the stairs, but if you do, prepare to wait for a ride and stop on every floor.!! THE ELEVATORS SUCK.!!!!!\\n2. Smokey Casino is okay, nothin special, 3-stars.\\n3. (2-stars) The smokey mid-way is old and could use a overhaul, but my 5-year old son knows no difference and loves it. The circus acts are entertaining too, this is why we come back every year. Very crowded so get used to bumping into folks. Adventure dome is fun too, but pricy. (Not smokey) The rides seem a little old and a little young for my 5-year old, so we didn't spend much time there this year. (3-stars).\\n4. Overall, this place is okay (2-stars), very smokey, pricy food, dirty, old; nice upgraded rooms but getting out during checkout time is a challenge because of the HORRIBLE ELEVATOR system. Circus Circus gets a well deserved 2-stars mostly because of the smokey venue and horrible elevators.\n",
      "\n",
      "Index: 2\n",
      "True Label: positive\n",
      "Predicted Label: negative\n",
      "Text: Did most my Christmas shopping at this TJMaxx Location. Went on a shopping spree and checked off most on my Christmas list! When I got home and unloaded my shopping bags, I realized I was missing 1 shopping bag with the delicate lacy dress. Called them right away and notified that I must have left my package. The lady who helped me was Nadia, and the manager's name I think is Laura. They couldn't find my shopping bag but told me to return, & graciously replaced the dress with another one as long as I have the receipt. Talk about customer service!!!\\n& Great deals as always!\n",
      "\n",
      "Index: 3\n",
      "True Label: positive\n",
      "Predicted Label: negative\n",
      "Text: JAYSUS!!! when will you guys open up in So Cal? In Vegas this weekend, hitting our old haunts...just missed you and could only lick the window out front!! ( ya I licked it! so what?) Had to head back to Big Bad So Cal...sobbing without a cupcake...*sniffle.\n",
      "\n",
      "Index: 4\n",
      "True Label: negative\n",
      "Predicted Label: positive\n",
      "Text: I've been to this location 1/2 dozen times and the food has always been Luke warm . I think today was my last time at this location.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Set the pandas option to display the full text\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Set the random seed\n",
    "random.seed(1)\n",
    "\n",
    "# These are the review texts\n",
    "texts = new_df['text']\n",
    "\n",
    "# Initialize variables to store the DataFrame for each model\n",
    "df_LiYuan = None\n",
    "df_cardiffnlp = None\n",
    "df_distilbert = None\n",
    "\n",
    "for model_name, predicted_labels in models.items():\n",
    "    # Initialize lists to store the samples\n",
    "    sample_true_labels = []\n",
    "    sample_predicted_labels = []\n",
    "    sample_texts = []\n",
    "    \n",
    "    # Get the indices of the incorrect predictions\n",
    "    incorrect_indices = [i for i, (true, pred) in enumerate(zip(true_sentiments, predicted_labels)) if true != pred and true.lower()!=\"neutral\" and pred.lower()!=\"neutral\"]\n",
    "    \n",
    "    # Randomly choose 5 samples\n",
    "    sample_indices = random.sample(incorrect_indices, 5)\n",
    "\n",
    "    # Store the true labels, predicted labels, and texts of the samples\n",
    "    for i in sample_indices:\n",
    "        sample_true_labels.append(true_sentiments[i])\n",
    "        sample_predicted_labels.append(predicted_labels[i])\n",
    "        # Split the text into tokens and select the first 512 tokens\n",
    "        tokens = texts[i].split()[:300]\n",
    "        # Join the tokens back into a string and store it\n",
    "        sample_texts.append(' '.join(tokens))\n",
    "    \n",
    "    # Create a DataFrame with the samples and store it in the corresponding variable\n",
    "    df = pd.DataFrame({\n",
    "        'True Label': sample_true_labels,\n",
    "        'Predicted Label': sample_predicted_labels,\n",
    "        'Text': sample_texts\n",
    "    })\n",
    "    if model_name == \"LiYuan\":\n",
    "        df_LiYuan = df\n",
    "    elif model_name == \"cardiffnlp\":\n",
    "        df_cardiffnlp = df\n",
    "    else: # model_name == \"distilbert\"\n",
    "        df_distilbert = df\n",
    "\n",
    "# Print the text for each row in the LiYuan model DataFrame\n",
    "print(\"\\nLiYuan model:\")\n",
    "for index, row in df_LiYuan.iterrows():\n",
    "    print(f\"Index: {index}\\nTrue Label: {row['True Label']}\\nPredicted Label: {row['Predicted Label']}\\nText: {row['Text']}\\n\")\n",
    "\n",
    "# Print the text for each row in the cardiffnlp model DataFrame\n",
    "print(\"\\ncardiffnlp model:\")\n",
    "for index, row in df_cardiffnlp.iterrows():\n",
    "    print(f\"Index: {index}\\nTrue Label: {row['True Label']}\\nPredicted Label: {row['Predicted Label']}\\nText: {row['Text']}\\n\")\n",
    "\n",
    "# Print the text for each row in the distilbert model DataFrame\n",
    "print(\"\\ndistilbert model:\")\n",
    "for index, row in df_distilbert.iterrows():\n",
    "    print(f\"Index: {index}\\nTrue Label: {row['True Label']}\\nPredicted Label: {row['Predicted Label']}\\nText: {row['Text']}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing the incorrect predictions made by models, i found that the types of mistakes made are mainly due to two reasons:\n",
    "\n",
    "Misunderstanding or overlooking the overall sentiment when the text contains both positive and negative aspects.\n",
    "\n",
    "Being misled by the initial sentiment expressed in the text and failing to consider the sentiment in the rest of the text.\n",
    "\n",
    "For example, the first sample reviewing text in LiYuan model, the text expresses dissatisfaction with a bakery’s service and menu changes. However, it starts with a positive sentiment (“I used to like Paradise Bakery a lot more than I do now”), which might have misled the model into predicting a positive sentiment. Another example is the third sample reviewing text in distilbert model, The text is generally positive, expressing satisfaction with the shopping experience and customer service. However, it also mentions a negative event (missing shopping bag). The model might have given too much weight to this negative event, leading to an incorrect negative prediction. \n",
    "\n",
    "It also can be proved by sentiment analysis using vader and textblob. When using vader and textblob to analyze thest texts where models made incorrect predictions, the mean and std number for vader_polarity textblob_polarity differs a lot. Besides, textblob_subjectivity is also high.The higher subjectivity means that the text contains more personal opinion rather than factual information, which also made it difficuty for models to give correct predictions.This suggests that the models could benefit from further training on a more diverse and balanced dataset, and possibly from improvements in their ability to understand and weigh the positive and negative aspects of the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/nanchen/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error polarity scores by rating:cardiffnlp_model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vader_polarity</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>textblob_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.620540</td>\n",
       "      <td>0.202539</td>\n",
       "      <td>0.534186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.487411</td>\n",
       "      <td>0.092203</td>\n",
       "      <td>0.107215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.223500</td>\n",
       "      <td>0.046184</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.656700</td>\n",
       "      <td>0.198958</td>\n",
       "      <td>0.480952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.784500</td>\n",
       "      <td>0.230952</td>\n",
       "      <td>0.580400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.908100</td>\n",
       "      <td>0.261600</td>\n",
       "      <td>0.586806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.976900</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.647772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vader_polarity  textblob_polarity  textblob_subjectivity\n",
       "count        5.000000           5.000000               5.000000\n",
       "mean         0.620540           0.202539               0.534186\n",
       "std          0.487411           0.092203               0.107215\n",
       "min         -0.223500           0.046184               0.375000\n",
       "25%          0.656700           0.198958               0.480952\n",
       "50%          0.784500           0.230952               0.580400\n",
       "75%          0.908100           0.261600               0.586806\n",
       "max          0.976900           0.275000               0.647772"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error polarity scores by rating:LiYuan_model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vader_polarity</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>textblob_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.71356</td>\n",
       "      <td>0.180409</td>\n",
       "      <td>0.583908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.34613</td>\n",
       "      <td>0.106591</td>\n",
       "      <td>0.109578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.10120</td>\n",
       "      <td>0.043509</td>\n",
       "      <td>0.428054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.80420</td>\n",
       "      <td>0.093571</td>\n",
       "      <td>0.527020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.83140</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.595714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.89850</td>\n",
       "      <td>0.246212</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.93250</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.693750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vader_polarity  textblob_polarity  textblob_subjectivity\n",
       "count         5.00000           5.000000               5.000000\n",
       "mean          0.71356           0.180409               0.583908\n",
       "std           0.34613           0.106591               0.109578\n",
       "min           0.10120           0.043509               0.428054\n",
       "25%           0.80420           0.093571               0.527020\n",
       "50%           0.83140           0.225000               0.595714\n",
       "75%           0.89850           0.246212               0.675000\n",
       "max           0.93250           0.293750               0.693750"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error polarity scores by rating:distilbert_model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vader_polarity</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>textblob_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.44500</td>\n",
       "      <td>0.141410</td>\n",
       "      <td>0.435125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.76258</td>\n",
       "      <td>0.160439</td>\n",
       "      <td>0.084991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.80350</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.22630</td>\n",
       "      <td>0.062449</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.91470</td>\n",
       "      <td>0.212013</td>\n",
       "      <td>0.411177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.91720</td>\n",
       "      <td>0.232589</td>\n",
       "      <td>0.454464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.97030</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.565539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vader_polarity  textblob_polarity  textblob_subjectivity\n",
       "count         5.00000           5.000000               5.000000\n",
       "mean          0.44500           0.141410               0.435125\n",
       "std           0.76258           0.160439               0.084991\n",
       "min          -0.80350          -0.100000               0.333333\n",
       "25%           0.22630           0.062449               0.411111\n",
       "50%           0.91470           0.212013               0.411177\n",
       "75%           0.91720           0.232589               0.454464\n",
       "max           0.97030           0.300000               0.565539"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "# Run Vader on the reviews\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_polarity(text):\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "# textblob\n",
    "def textblob_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "def textblob_subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "\n",
    "def error_polarity_scores_by_rating(df, model_name):\n",
    "    df['vader_polarity'] = df['Text'].apply(vader_polarity)\n",
    "    df['textblob_polarity'] = df['Text'].apply(textblob_polarity)\n",
    "    df['textblob_subjectivity'] = df['Text'].apply(textblob_subjectivity)\n",
    "    print(\"Error polarity scores by rating:\" + model_name)\n",
    "    return display(df.describe()[['vader_polarity', 'textblob_polarity', 'textblob_subjectivity']])\n",
    "\n",
    "error_polarity_scores_by_rating(df_cardiffnlp, \"cardiffnlp_model\")\n",
    "error_polarity_scores_by_rating(df_LiYuan, \"LiYuan_model\")\n",
    "error_polarity_scores_by_rating(df_distilbert, \"distilbert_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification Tasks: Zero Shot Classification\n",
    "## 3.a. Based on Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 30, but your input_length is only 14. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=7)\n",
      "Your max_length is set to 30, but your input_length is only 6. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=3)\n",
      "Your max_length is set to 30, but your input_length is only 6. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=3)\n",
      "Your max_length is set to 30, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 30, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n",
      "Your max_length is set to 30, but your input_length is only 15. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=7)\n",
      "Your max_length is set to 30, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
      "Your max_length is set to 30, but your input_length is only 17. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n",
      "Your max_length is set to 30, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 30, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 30, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 30, but your input_length is only 16. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n",
      "Your max_length is set to 30, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n",
      "Your max_length is set to 30, but your input_length is only 13. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text  \\\n",
      "0    dr. goldberg offers everything i look for in a...   \n",
      "1    Unfortunately, the frustration of being Dr. Go...   \n",
      "2    Been going to Dr. Goldberg for over 10 years. ...   \n",
      "3    Got a letter in the mail last week that said D...   \n",
      "4    I don't know what Dr. Goldberg was like before...   \n",
      "..                                                 ...   \n",
      "145  Even when we didn't have a car Filene's Baseme...   \n",
      "146  Love this store!  Don't always have much luck ...   \n",
      "147  Another store which has gone the way of the Do...   \n",
      "148  $9.75 for a red bull and vodka? I'm sorry, I t...   \n",
      "149  Really enjoyed this a lot more than I thought ...   \n",
      "\n",
      "                                               summary  stars  \n",
      "0     dr. goldberg offers everything i look for in ...      4  \n",
      "1    The frustration of being Dr. Goldberg's patien...      1  \n",
      "2    I've been going to Dr. Goldberg for over 10 ye...      3  \n",
      "3    Dr. Goldberg is moving to Arizona to take a ne...      3  \n",
      "4    Dr. Goldberg is only interested in the co-pay ...      0  \n",
      "..                                                 ...    ...  \n",
      "145  Filene's Basement was worth the bus trip to th...      3  \n",
      "146  \"Don't always have much luck with the sales, b...      4  \n",
      "147  There was nothing basement like about it. What...      1  \n",
      "148  $9.75 for a red bull and vodka? I'm sorry, I t...      1  \n",
      "149  The drinks were on the pricey side, but I didn...      2  \n",
      "\n",
      "[150 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Create a text summarization pipeline using the BART model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Initialize an empty list to store summaries\n",
    "summaries = []\n",
    "\n",
    "# Dynamically adjust max_length and summarize the text\n",
    "for text in df['text'].iloc[:150].tolist():\n",
    "    input_length = len(text.split())  # Estimate the number of words in the input\n",
    "    max_length = min(130, max(30, int(input_length * 0.5)))  # Dynamically adjust max_length\n",
    "    summary = summarizer(text, max_length=max_length, min_length=30, truncation=True)[0]['summary_text']\n",
    "    summaries.append(summary)\n",
    "\n",
    "# Create a new dataframe to store the original texts and their summaries\n",
    "# Make sure to also copy the star rating information, assuming in the original dataset the star rating is stored in the 'label' column\n",
    "df_summary = df.iloc[:150].copy()  # Copy the first 150 rows\n",
    "df_summary['summary'] = summaries  # Add the summaries to the new dataframe\n",
    "df_summary['stars'] = df['label'].iloc[:150]  # Copy the corresponding star ratings\n",
    "\n",
    "print(df_summary[['text', 'summary', 'stars']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class YelpReviewDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels   # Convert labels from 1-5 to 0-4\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Prepare the data\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "X = df_summary['summary'].tolist()  # Summary texts\n",
    "y = df_summary['stars'].to_numpy()  # Star ratings\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=2021)\n",
    "\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "train_dataset = YelpReviewDataset(train_encodings, y_train)\n",
    "val_dataset = YelpReviewDataset(val_encodings, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition, Training and Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Yue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "  0%|          | 0/45 [24:05<?, ?it/s]\n",
      "                                      \n",
      "  0%|          | 0/45 [18:57<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.653, 'grad_norm': 5.85977840423584, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \n",
      "  0%|          | 0/45 [19:48<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6375, 'grad_norm': 6.079554080963135, 'learning_rate': 2.0000000000000003e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \n",
      "  0%|          | 0/45 [20:38<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6171, 'grad_norm': 4.7647199630737305, 'learning_rate': 3e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \n",
      "  0%|          | 0/45 [21:27<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6226, 'grad_norm': 6.65775728225708, 'learning_rate': 4.000000000000001e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \n",
      "100%|██████████| 45/45 [03:43<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 223.4901, 'train_samples_per_second': 1.611, 'train_steps_per_second': 0.201, 'train_loss': 1.6244254642062717, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6399976015090942,\n",
       " 'eval_runtime': 4.3772,\n",
       " 'eval_samples_per_second': 6.854,\n",
       " 'eval_steps_per_second': 0.914,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Result List\n",
    "5   'train_loss': 1.1762760480244954 'eval_loss': 1.5997843742370605\n",
    "\n",
    "15  'train_loss': 1.3541520436604817 'eval_loss': 0.7361515164375305\n",
    "\n",
    "30  'train_loss': 1.2990621990627713 'eval_loss': 1.175505518913269\n",
    "\n",
    "100 'train_loss': 1.2386985460917155 'eval_loss': 1.1782324314117432\n",
    "\n",
    "150 'train_loss': 1.1339557965596516 'eval_loss': 1.2087987661361694\n",
    "\n",
    "The second result in the list shows an intriguing case where the evaluation loss is significantly lower than the training loss. This is an unusual scenario in machine learning models because typically, the training loss is lower due to the model being directly trained on that data. Here, an eval_loss of 0.736 compared to a train_loss of 1.354 suggests a few possible scenarios:\n",
    "\n",
    "Strong Generalization: The model may generalize exceptionally well to the validation data, possibly because the validation set characteristics closely match the model's training data, or the model has learned robust features that work well across varied data samples.\n",
    "\n",
    "Data Distribution: The distribution of data in the training set might be more challenging or diverse compared to the evaluation set, which can lead to higher training loss.\n",
    "\n",
    "Evaluation Set Size: If the evaluation set is significantly smaller or not as diverse, it might not represent the difficulty of the overall dataset, leading to a deceptively low evaluation loss.\n",
    "\n",
    "Overfitting Avoidance: It's also possible that certain regularization techniques or early stopping mechanisms were effective in preventing the model from overfitting, hence the model performs better on unseen data.\n",
    "\n",
    "Random Variation: Especially with smaller datasets, random variation can sometimes lead to situations where evaluation loss is lower than training loss.\n",
    "\n",
    "### The number 300 is used to specify the number of text entries from the Yelp review dataset that we want to process.\n",
    "\n",
    "1.Data Selection: df['text'].iloc[:300].tolist() – This line selects the first 300 entries from the 'text' column of the dataframe df. The .iloc[:300] is an indexing operation used in pandas to select data by position. Here, it slices the first 300 rows of the dataframe.\n",
    "\n",
    "2.Summarization Process: The loop for text in df['text'].iloc[:300].tolist() iterates over each of the first 300 text entries. For each text, the script estimates the input length, adjusts the maximum summary length accordingly, and then generates a summary using the BART model.\n",
    "\n",
    "### Ideal Range\n",
    "\n",
    "Close to 0 but not 0: Ideally, the loss value should be close to 0, which indicates that the model's predictions are very close to the actual labels. However, a loss value of 0 might suggest that the model is overfitting on the training set, perfectly memorizing the training data, which could lead to poor performance on unseen data.\n",
    "\n",
    "Eval loss close to train loss: If the evaluation loss (eval_loss) and training loss (train_loss) are very close, it is usually a good sign, indicating that the model performs consistently on both the training and validation sets, demonstrating good generalization ability.\n",
    "\n",
    "### Specific Range\n",
    "\n",
    "Loss value: The specific range of loss values greatly depends on the characteristics of the dataset and the complexity of the model. For some tasks, such as simple classification problems, the loss value might be between 0.01 and 0.5. For more complex tasks or more challenging datasets, the loss value might range from 1 to 10, or even higher.\n",
    "\n",
    "Difference: The difference between the training loss and evaluation loss should be as small as possible. A good rule of thumb is that the difference should not exceed 10% to 20% of the training loss. For example, if the train_loss is 0.5, the eval_loss should ideally be between 0.5 and 0.6.\n",
    "\n",
    "### Loss Values in Our Model\n",
    "\n",
    "Training Loss (train_loss) of 1.1339557965596516: This indicates the average degree of error the model has when recognizing patterns in the training data. For a complex NLP task, this value might be considered reasonable in the initial stages, especially considering the use of a large pre-trained model and a complex dataset.\n",
    "\n",
    "Evaluation Loss (eval_loss) of 1.2087987661361694: This is slightly higher than the training loss. Such a scenario is common in machine learning models, as the evaluation loss represents the model's performance on unseen data, which is usually slightly higher than the training loss.\n",
    "\n",
    "### Judging Whether Loss Values are \"High\" or \"Low\"\n",
    "\n",
    "Generally, for text classification tasks, if both training and evaluation losses are below 1.0, this is usually considered good performance. However, even if loss values are between 1.0 and 2.0, this may still be acceptable performance depending on the task's complexity and the characteristics of the dataset.\n",
    "\n",
    "It's important to monitor how loss values change with training progress. Ideally, you would want to see both training and evaluation losses gradually decrease as the number of epochs increases, and the gap between them should not significantly widen over time, as this may indicate overfitting.\n",
    "\n",
    "## 3.b. Zero-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randly select 100 samples\n",
    "df = df.sample(100)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Manually add categories to each review and import the dataset\n",
    "df = pd.read_csv('yelp_review_full.csv')\n",
    "# Define categories\n",
    "classes = [\"Restaurants\", \"Bars\", \"Coffee Shops\", \"Hotels\", \"Salons/Barbershops\",\n",
    "           \"Auto Repair\", \"Home Services\", \"Medical Services\", \"Entertainment\", \"Pet Services\",\n",
    "           \"Financial Services\", \"Travel & Tourism\", \"Education\", \"Real Estate\", \"Fitness\",\n",
    "           \"Landscaping & Gardening Services\", \"Legal Services\", \"Photography Services\",\n",
    "           \"Childcare Services\", \"Computer & Technology Services\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text  \\\n",
      "0      4  I've been going here for about 4 yrs.Cleanest ...   \n",
      "1      1  We've wanted to try Thai E-San since they open...   \n",
      "2      0  The food is ok but the service is terrible!!!!...   \n",
      "3      3  There's typically a 15-20 minute wait when we ...   \n",
      "4      3  Five guys offers a basic selection of burgers,...   \n",
      "\n",
      "      Manual_Category         model1  \n",
      "0  Salons/Barbershops  Entertainment  \n",
      "1         Restaurants    Restaurants  \n",
      "2         Restaurants    Restaurants  \n",
      "3         Restaurants    Restaurants  \n",
      "4         Restaurants    Restaurants  \n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Model 1: facebook/bart-large-mnli\n",
    "classifier_1 = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "def model1_review(text):\n",
    "    result = classifier_1(text, candidate_labels=classes, multi_label=True)\n",
    "    return result['labels'][0]  # Returning the top category\n",
    "\n",
    "# Apply the function to each review in the DataFrame\n",
    "df['model1'] = df['text'].apply(model1_review)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type T5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text  \\\n",
      "0      4  I've been going here for about 4 yrs.Cleanest ...   \n",
      "1      1  We've wanted to try Thai E-San since they open...   \n",
      "2      0  The food is ok but the service is terrible!!!!...   \n",
      "3      3  There's typically a 15-20 minute wait when we ...   \n",
      "4      3  Five guys offers a basic selection of burgers,...   \n",
      "\n",
      "      Manual_Category         model1         model2  \n",
      "0  Salons/Barbershops  Entertainment  Home Services  \n",
      "1         Restaurants    Restaurants   Pet Services  \n",
      "2         Restaurants    Restaurants    Restaurants  \n",
      "3         Restaurants    Restaurants    Restaurants  \n",
      "4         Restaurants    Restaurants    Restaurants  \n"
     ]
    }
   ],
   "source": [
    "# Model 2: knowledgator/comprehend_it-multilingual-t5-base\n",
    "# pip install liqfit sentencepiece\n",
    "from liqfit.pipeline import ZeroShotClassificationPipeline\n",
    "from liqfit.models import T5ForZeroShotClassification\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "model = T5ForZeroShotClassification.from_pretrained('knowledgator/comprehend_it-multilingual-t5-base')\n",
    "tokenizer = T5Tokenizer.from_pretrained('knowledgator/comprehend_it-multilingual-t5-base')\n",
    "classifier_2 = ZeroShotClassificationPipeline(model=model, tokenizer=tokenizer,\n",
    "                                                      hypothesis_template = '{}', encoder_decoder = True)\n",
    "def model2_review(text):\n",
    "    result = classifier_2(text, candidate_labels=classes, multi_label=True)\n",
    "    return result['labels'][0]  # Returning the top category\n",
    "\n",
    "# Apply the function to each review in the DataFrame\n",
    "df['model2'] = df['text'].apply(model2_review)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Yue\\.cache\\huggingface\\hub\\models--MoritzLaurer--DeBERTa-v3-base-mnli-fever-anli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yue\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDebertaV2ForSequenceClassification: ['deberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFDebertaV2ForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDebertaV2ForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDebertaV2ForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2ForSequenceClassification for predictions without further training.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text  \\\n",
      "0      4  I've been going here for about 4 yrs.Cleanest ...   \n",
      "1      1  We've wanted to try Thai E-San since they open...   \n",
      "2      0  The food is ok but the service is terrible!!!!...   \n",
      "3      3  There's typically a 15-20 minute wait when we ...   \n",
      "4      3  Five guys offers a basic selection of burgers,...   \n",
      "\n",
      "      Manual_Category         model1         model2              model3  \n",
      "0  Salons/Barbershops  Entertainment  Home Services  Salons/Barbershops  \n",
      "1         Restaurants    Restaurants   Pet Services         Restaurants  \n",
      "2         Restaurants    Restaurants    Restaurants         Restaurants  \n",
      "3         Restaurants    Restaurants    Restaurants         Restaurants  \n",
      "4         Restaurants    Restaurants    Restaurants         Restaurants  \n"
     ]
    }
   ],
   "source": [
    "# Model 3: MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\n",
    "# pip install transformers[sentencepiece]\n",
    "from transformers import pipeline\n",
    "classifier_3 = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")\n",
    "def model3_review(text):\n",
    "    result = classifier_3(text, candidate_labels=classes, multi_label=True)\n",
    "    return result['labels'][0]  # Returning the top category\n",
    "\n",
    "# Apply the function to each review in the DataFrame\n",
    "df['model3'] = df['text'].apply(model3_review)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison and Accuracy Calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 1:  0.61\n",
      "Accuracy of model 2:  0.59\n",
      "Accuracy of model 3:  0.73\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = (df['model1'] == df['Manual_Category']).mean()\n",
    "accuracy2 = (df['model2'] == df['Manual_Category']).mean()\n",
    "accuracy3 = (df['model3'] == df['Manual_Category']).mean()\n",
    "print(\"Accuracy of model 1: \", accuracy1)\n",
    "print(\"Accuracy of model 2: \", accuracy2)\n",
    "print(\"Accuracy of model 3: \", accuracy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: facebook/bart-large-mnli\n",
    "Accuracy: 61%\n",
    "\n",
    "This model uses a combined bidirectional encoder and autoregressive decoder, trained on the MNLI dataset. Its moderate accuracy suggests that while effective at general language tasks, it may not fully capture the specific nuances of Yelp reviews.\n",
    "\n",
    "### Model 2: knowledgator/comprehend_it-multilingual-t5-base\n",
    "Accuracy: 59%\n",
    "\n",
    "Based on the T5 architecture, which processes tasks as text generation in multiple languages, its slightly lower performance might stem from its generalist training which is not specialized enough for the particular characteristics of Yelp reviews.\n",
    "\n",
    "### Model 3: MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\n",
    "Accuracy: 73%\n",
    "\n",
    "DeBERTa enhances BERT architectures with a novel attention mechanism and is further fine-tuned on datasets aimed at improving inference, resulting in the highest accuracy among the three models. This suggests superior handling of the complex semantics in review texts.\n",
    "\n",
    "\n",
    "In summary, the varying accuracies reflect each model’s architectural strengths and training focus, with DeBERTa standing out due to its advanced inference capabilities and specialized attention mechanism."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS6120",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
